2025-11-24 07:43:26,193 [trainer.py] => config: exps/cpt_c100.json
2025-11-24 07:43:26,195 [trainer.py] => prefix: reproduce
2025-11-24 07:43:26,195 [trainer.py] => dataset: cifar224
2025-11-24 07:43:26,195 [trainer.py] => memory_size: 0
2025-11-24 07:43:26,195 [trainer.py] => memory_per_class: 0
2025-11-24 07:43:26,195 [trainer.py] => fixed_memory: False
2025-11-24 07:43:26,195 [trainer.py] => shuffle: True
2025-11-24 07:43:26,195 [trainer.py] => init_cls: 10
2025-11-24 07:43:26,195 [trainer.py] => increment: 10
2025-11-24 07:43:26,195 [trainer.py] => model_name: cpt
2025-11-24 07:43:26,195 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-24 07:43:26,195 [trainer.py] => get_original_backbone: True
2025-11-24 07:43:26,195 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-24 07:43:26,195 [trainer.py] => seed: 0
2025-11-24 07:43:26,195 [trainer.py] => tuned_epoch: 10
2025-11-24 07:43:26,195 [trainer.py] => init_lr: 0.001
2025-11-24 07:43:26,195 [trainer.py] => cpt_first_lr: 0.001
2025-11-24 07:43:26,195 [trainer.py] => cpt_first_epochs: 20
2025-11-24 07:43:26,195 [trainer.py] => cpt_meta_lr: 0.001
2025-11-24 07:43:26,195 [trainer.py] => cpt_meta_epochs: 10
2025-11-24 07:43:26,195 [trainer.py] => batch_size: 16
2025-11-24 07:43:26,195 [trainer.py] => weight_decay: 0.0
2025-11-24 07:43:26,195 [trainer.py] => min_lr: 1e-05
2025-11-24 07:43:26,196 [trainer.py] => optimizer: adam
2025-11-24 07:43:26,196 [trainer.py] => scheduler: constant
2025-11-24 07:43:26,196 [trainer.py] => reinit_optimizer: True
2025-11-24 07:43:26,196 [trainer.py] => global_pool: token
2025-11-24 07:43:26,196 [trainer.py] => head_type: prompt
2025-11-24 07:43:26,196 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2025-11-24 07:43:26,196 [trainer.py] => pretrained: True
2025-11-24 07:43:26,196 [trainer.py] => drop: 0.0
2025-11-24 07:43:26,196 [trainer.py] => drop_path: 0.0
2025-11-24 07:43:26,196 [trainer.py] => prompt_pool: True
2025-11-24 07:43:26,196 [trainer.py] => size: 10
2025-11-24 07:43:26,196 [trainer.py] => length: 5
2025-11-24 07:43:26,196 [trainer.py] => top_k: 5
2025-11-24 07:43:26,196 [trainer.py] => initializer: uniform
2025-11-24 07:43:26,196 [trainer.py] => prompt_key: True
2025-11-24 07:43:26,196 [trainer.py] => prompt_key_init: uniform
2025-11-24 07:43:26,196 [trainer.py] => use_prompt_mask: False
2025-11-24 07:43:26,196 [trainer.py] => shared_prompt_pool: False
2025-11-24 07:43:26,196 [trainer.py] => shared_prompt_key: False
2025-11-24 07:43:26,196 [trainer.py] => batchwise_prompt: True
2025-11-24 07:43:26,196 [trainer.py] => embedding_key: cls
2025-11-24 07:43:26,196 [trainer.py] => predefined_key: 
2025-11-24 07:43:26,196 [trainer.py] => pull_constraint: True
2025-11-24 07:43:26,196 [trainer.py] => pull_constraint_coeff: 0.1
2025-11-24 07:43:26,196 [trainer.py] => mask_old_classes: False
2025-11-24 07:43:28,145 [data_manager.py] => [26, 86, 2, 55, 75, 93, 16, 73, 54, 95, 53, 92, 78, 13, 7, 30, 22, 24, 33, 8, 43, 62, 3, 71, 45, 48, 6, 99, 82, 76, 60, 80, 90, 68, 51, 27, 18, 56, 63, 74, 1, 61, 42, 41, 4, 15, 17, 40, 38, 5, 91, 59, 0, 34, 28, 50, 11, 35, 23, 52, 10, 31, 66, 57, 79, 85, 32, 84, 14, 89, 19, 29, 49, 97, 98, 69, 20, 94, 72, 77, 25, 37, 81, 46, 39, 65, 58, 12, 88, 70, 87, 36, 21, 83, 9, 96, 67, 64, 47, 44]
2025-11-24 07:43:30,128 [_builder.py] => Loading pretrained weights from url (https://storage.googleapis.com/vit_models/augreg/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz)
2025-11-24 07:43:30,146 [vit_cpt.py] => Pretrained npz load failed for vit_base_patch16_224_cpt (Expected hasRecord("version") to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)); retrying without pretrained weights.
2025-11-24 07:43:32,266 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-24 07:43:32,903 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-24 07:43:33,299 [_builder.py] => Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
2025-11-24 07:43:33,318 [cpt.py] => 85,948,516 model total parameters.
2025-11-24 07:43:33,319 [cpt.py] => 130,660 model training parameters.
2025-11-24 07:43:33,319 [cpt.py] => prompt.first_prompt: 3840
2025-11-24 07:43:33,319 [cpt.py] => prompt.prompt: 38400
2025-11-24 07:43:33,319 [cpt.py] => prompt.meta_prompt: 3840
2025-11-24 07:43:33,319 [cpt.py] => prompt.prompt_key: 7680
2025-11-24 07:43:33,320 [cpt.py] => head.weight: 76800
2025-11-24 07:43:33,320 [cpt.py] => head.bias: 100
2025-11-24 07:43:33,321 [trainer.py] => All params: 171824072
2025-11-24 07:43:33,322 [trainer.py] => Trainable params: 130660
2025-11-24 07:43:33,322 [cpt.py] => Learning on 0-10
2025-11-24 07:43:34,355 [cpt.py] => Training first_prompt for task 0
2025-11-24 08:00:00,641 [cpt.py] => Task 0, Epoch 20/20 => Loss 1.826, Train_accy 33.64, Test_accy 37.00
2025-11-24 08:00:07,253 [trainer.py] => No NME accuracy.
2025-11-24 08:00:07,254 [trainer.py] => CNN: {'total': np.float64(37.0), '00-09': np.float64(37.0), 'old': 0, 'new': np.float64(37.0)}
2025-11-24 08:00:07,254 [trainer.py] => CNN top1 curve: [np.float64(37.0)]
2025-11-24 08:00:07,254 [trainer.py] => CNN top5 curve: [np.float64(85.6)]

2025-11-24 08:00:07,255 [trainer.py] => Average Accuracy (CNN): 37.0 

2025-11-24 08:00:07,256 [trainer.py] => All params: 171824072
2025-11-24 08:00:07,257 [trainer.py] => Trainable params: 130660
2025-11-24 08:00:07,257 [cpt.py] => Learning on 10-20
2025-11-24 08:00:07,329 [cpt.py] => Training prompt for task 1
2025-11-27 06:26:27,299 [trainer.py] => config: exps/cpt_c100.json
2025-11-27 06:26:27,302 [trainer.py] => prefix: reproduce
2025-11-27 06:26:27,302 [trainer.py] => dataset: cifar224
2025-11-27 06:26:27,302 [trainer.py] => memory_size: 0
2025-11-27 06:26:27,302 [trainer.py] => memory_per_class: 0
2025-11-27 06:26:27,302 [trainer.py] => fixed_memory: False
2025-11-27 06:26:27,302 [trainer.py] => shuffle: True
2025-11-27 06:26:27,302 [trainer.py] => init_cls: 10
2025-11-27 06:26:27,303 [trainer.py] => increment: 10
2025-11-27 06:26:27,303 [trainer.py] => model_name: cpt
2025-11-27 06:26:27,303 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 06:26:27,303 [trainer.py] => get_original_backbone: True
2025-11-27 06:26:27,303 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 06:26:27,303 [trainer.py] => seed: 0
2025-11-27 06:26:27,303 [trainer.py] => tuned_epoch: 10
2025-11-27 06:26:27,303 [trainer.py] => init_lr: 0.001
2025-11-27 06:26:27,303 [trainer.py] => cpt_first_lr: 0.001
2025-11-27 06:26:27,303 [trainer.py] => cpt_first_epochs: 20
2025-11-27 06:26:27,303 [trainer.py] => cpt_meta_lr: 0.001
2025-11-27 06:26:27,303 [trainer.py] => cpt_meta_epochs: 10
2025-11-27 06:26:27,303 [trainer.py] => batch_size: 16
2025-11-27 06:26:27,303 [trainer.py] => weight_decay: 0.0
2025-11-27 06:26:27,303 [trainer.py] => min_lr: 1e-05
2025-11-27 06:26:27,304 [trainer.py] => optimizer: adam
2025-11-27 06:26:27,304 [trainer.py] => scheduler: constant
2025-11-27 06:26:27,304 [trainer.py] => reinit_optimizer: True
2025-11-27 06:26:27,304 [trainer.py] => global_pool: token
2025-11-27 06:26:27,304 [trainer.py] => head_type: prompt
2025-11-27 06:26:27,304 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2025-11-27 06:26:27,304 [trainer.py] => pretrained: True
2025-11-27 06:26:27,304 [trainer.py] => drop: 0.0
2025-11-27 06:26:27,304 [trainer.py] => drop_path: 0.0
2025-11-27 06:26:27,304 [trainer.py] => prompt_pool: True
2025-11-27 06:26:27,304 [trainer.py] => size: 10
2025-11-27 06:26:27,304 [trainer.py] => length: 5
2025-11-27 06:26:27,304 [trainer.py] => top_k: 5
2025-11-27 06:26:27,304 [trainer.py] => initializer: uniform
2025-11-27 06:26:27,304 [trainer.py] => prompt_key: True
2025-11-27 06:26:27,304 [trainer.py] => prompt_key_init: uniform
2025-11-27 06:26:27,304 [trainer.py] => use_prompt_mask: False
2025-11-27 06:26:27,305 [trainer.py] => shared_prompt_pool: False
2025-11-27 06:26:27,305 [trainer.py] => shared_prompt_key: False
2025-11-27 06:26:27,305 [trainer.py] => batchwise_prompt: True
2025-11-27 06:26:27,305 [trainer.py] => embedding_key: cls
2025-11-27 06:26:27,305 [trainer.py] => predefined_key: 
2025-11-27 06:26:27,305 [trainer.py] => pull_constraint: True
2025-11-27 06:26:27,305 [trainer.py] => pull_constraint_coeff: 0.1
2025-11-27 06:26:27,305 [trainer.py] => mask_old_classes: False
2025-11-27 06:26:29,315 [data_manager.py] => [26, 86, 2, 55, 75, 93, 16, 73, 54, 95, 53, 92, 78, 13, 7, 30, 22, 24, 33, 8, 43, 62, 3, 71, 45, 48, 6, 99, 82, 76, 60, 80, 90, 68, 51, 27, 18, 56, 63, 74, 1, 61, 42, 41, 4, 15, 17, 40, 38, 5, 91, 59, 0, 34, 28, 50, 11, 35, 23, 52, 10, 31, 66, 57, 79, 85, 32, 84, 14, 89, 19, 29, 49, 97, 98, 69, 20, 94, 72, 77, 25, 37, 81, 46, 39, 65, 58, 12, 88, 70, 87, 36, 21, 83, 9, 96, 67, 64, 47, 44]
2025-11-27 06:26:31,368 [_builder.py] => Loading pretrained weights from url (https://storage.googleapis.com/vit_models/augreg/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz)
2025-11-27 06:26:31,388 [vit_cpt.py] => Pretrained npz load failed for vit_base_patch16_224_cpt (Expected hasRecord("version") to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)); retrying without pretrained weights.
2025-11-27 06:26:33,500 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-27 06:26:33,871 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 06:26:36,400 [_builder.py] => Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
2025-11-27 06:26:36,424 [cpt.py] => 85,948,516 model total parameters.
2025-11-27 06:26:36,425 [cpt.py] => 130,660 model training parameters.
2025-11-27 06:26:36,425 [cpt.py] => prompt.first_prompt: 3840
2025-11-27 06:26:36,425 [cpt.py] => prompt.prompt: 38400
2025-11-27 06:26:36,426 [cpt.py] => prompt.meta_prompt: 3840
2025-11-27 06:26:36,426 [cpt.py] => prompt.prompt_key: 7680
2025-11-27 06:26:36,427 [cpt.py] => head.weight: 76800
2025-11-27 06:26:36,427 [cpt.py] => head.bias: 100
2025-11-27 06:26:36,428 [trainer.py] => All params: 171824072
2025-11-27 06:26:36,429 [trainer.py] => Trainable params: 130660
2025-11-27 06:26:36,430 [cpt.py] => Learning on 0-10
2025-11-27 06:26:37,471 [cpt.py] => Training first_prompt for task 0
2025-11-27 06:34:07,844 [trainer.py] => config: exps/cpt_c100.json
2025-11-27 06:34:07,845 [trainer.py] => prefix: reproduce
2025-11-27 06:34:07,845 [trainer.py] => dataset: cifar224
2025-11-27 06:34:07,845 [trainer.py] => memory_size: 0
2025-11-27 06:34:07,845 [trainer.py] => memory_per_class: 0
2025-11-27 06:34:07,845 [trainer.py] => fixed_memory: False
2025-11-27 06:34:07,845 [trainer.py] => shuffle: True
2025-11-27 06:34:07,845 [trainer.py] => init_cls: 10
2025-11-27 06:34:07,845 [trainer.py] => increment: 10
2025-11-27 06:34:07,845 [trainer.py] => model_name: cpt
2025-11-27 06:34:07,845 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 06:34:07,845 [trainer.py] => get_original_backbone: True
2025-11-27 06:34:07,845 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 06:34:07,845 [trainer.py] => seed: 0
2025-11-27 06:34:07,845 [trainer.py] => tuned_epoch: 10
2025-11-27 06:34:07,845 [trainer.py] => init_lr: 0.001
2025-11-27 06:34:07,846 [trainer.py] => cpt_first_lr: 0.001
2025-11-27 06:34:07,846 [trainer.py] => cpt_first_epochs: 20
2025-11-27 06:34:07,846 [trainer.py] => cpt_meta_lr: 0.001
2025-11-27 06:34:07,846 [trainer.py] => cpt_meta_epochs: 10
2025-11-27 06:34:07,846 [trainer.py] => batch_size: 16
2025-11-27 06:34:07,846 [trainer.py] => weight_decay: 0.0
2025-11-27 06:34:07,846 [trainer.py] => min_lr: 1e-05
2025-11-27 06:34:07,846 [trainer.py] => optimizer: adam
2025-11-27 06:34:07,846 [trainer.py] => scheduler: constant
2025-11-27 06:34:07,846 [trainer.py] => reinit_optimizer: True
2025-11-27 06:34:07,846 [trainer.py] => global_pool: token
2025-11-27 06:34:07,846 [trainer.py] => head_type: prompt
2025-11-27 06:34:07,847 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2025-11-27 06:34:07,847 [trainer.py] => pretrained: True
2025-11-27 06:34:07,847 [trainer.py] => drop: 0.0
2025-11-27 06:34:07,847 [trainer.py] => drop_path: 0.0
2025-11-27 06:34:07,847 [trainer.py] => prompt_pool: True
2025-11-27 06:34:07,847 [trainer.py] => size: 10
2025-11-27 06:34:07,847 [trainer.py] => length: 5
2025-11-27 06:34:07,847 [trainer.py] => top_k: 5
2025-11-27 06:34:07,847 [trainer.py] => initializer: uniform
2025-11-27 06:34:07,847 [trainer.py] => prompt_key: True
2025-11-27 06:34:07,847 [trainer.py] => prompt_key_init: uniform
2025-11-27 06:34:07,847 [trainer.py] => use_prompt_mask: False
2025-11-27 06:34:07,847 [trainer.py] => shared_prompt_pool: False
2025-11-27 06:34:07,847 [trainer.py] => shared_prompt_key: False
2025-11-27 06:34:07,847 [trainer.py] => batchwise_prompt: True
2025-11-27 06:34:07,847 [trainer.py] => embedding_key: cls
2025-11-27 06:34:07,847 [trainer.py] => predefined_key: 
2025-11-27 06:34:07,847 [trainer.py] => pull_constraint: True
2025-11-27 06:34:07,847 [trainer.py] => pull_constraint_coeff: 0.1
2025-11-27 06:34:07,847 [trainer.py] => mask_old_classes: False
2025-11-27 06:34:09,783 [data_manager.py] => [26, 86, 2, 55, 75, 93, 16, 73, 54, 95, 53, 92, 78, 13, 7, 30, 22, 24, 33, 8, 43, 62, 3, 71, 45, 48, 6, 99, 82, 76, 60, 80, 90, 68, 51, 27, 18, 56, 63, 74, 1, 61, 42, 41, 4, 15, 17, 40, 38, 5, 91, 59, 0, 34, 28, 50, 11, 35, 23, 52, 10, 31, 66, 57, 79, 85, 32, 84, 14, 89, 19, 29, 49, 97, 98, 69, 20, 94, 72, 77, 25, 37, 81, 46, 39, 65, 58, 12, 88, 70, 87, 36, 21, 83, 9, 96, 67, 64, 47, 44]
2025-11-27 06:34:11,983 [vit_cpt.py] => Failed to load pretrained weights for vit_base_patch16_224_cpt: The size of tensor a (222) must match the size of tensor b (197) at non-singleton dimension 1
Traceback: Traceback (most recent call last):
  File "/root/PEFT-CL/backbone/vit_cpt.py", line 666, in _create_vision_transformer
    model.load_pretrained(checkpoint_path)
  File "/root/PEFT-CL/backbone/vit_cpt.py", line 387, in load_pretrained
    _load_weights(self, checkpoint_path, prefix)
  File "/root/micromamba/envs/PEFT-CL/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/root/PEFT-CL/backbone/vit_cpt.py", line 585, in _load_weights
    model.pos_embed.copy_(pos_embed_w)
RuntimeError: The size of tensor a (222) must match the size of tensor b (197) at non-singleton dimension 1

Continuing with randomly initialized weights.
2025-11-27 06:34:13,105 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-27 06:34:13,435 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 06:34:13,826 [_builder.py] => Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
2025-11-27 06:34:13,849 [cpt.py] => 85,948,516 model total parameters.
2025-11-27 06:34:13,850 [cpt.py] => 130,660 model training parameters.
2025-11-27 06:34:13,851 [cpt.py] => prompt.first_prompt: 3840
2025-11-27 06:34:13,851 [cpt.py] => prompt.prompt: 38400
2025-11-27 06:34:13,851 [cpt.py] => prompt.meta_prompt: 3840
2025-11-27 06:34:13,851 [cpt.py] => prompt.prompt_key: 7680
2025-11-27 06:34:13,851 [cpt.py] => head.weight: 76800
2025-11-27 06:34:13,851 [cpt.py] => head.bias: 100
2025-11-27 06:34:13,853 [trainer.py] => All params: 171824072
2025-11-27 06:34:13,855 [trainer.py] => Trainable params: 130660
2025-11-27 06:34:13,855 [cpt.py] => Learning on 0-10
2025-11-27 06:34:15,305 [cpt.py] => Training first_prompt for task 0
2025-11-27 06:40:50,569 [trainer.py] => config: exps/cpt_c100.json
2025-11-27 06:40:50,570 [trainer.py] => prefix: reproduce
2025-11-27 06:40:50,570 [trainer.py] => dataset: cifar224
2025-11-27 06:40:50,570 [trainer.py] => memory_size: 0
2025-11-27 06:40:50,570 [trainer.py] => memory_per_class: 0
2025-11-27 06:40:50,570 [trainer.py] => fixed_memory: False
2025-11-27 06:40:50,570 [trainer.py] => shuffle: True
2025-11-27 06:40:50,570 [trainer.py] => init_cls: 10
2025-11-27 06:40:50,571 [trainer.py] => increment: 10
2025-11-27 06:40:50,571 [trainer.py] => model_name: cpt
2025-11-27 06:40:50,571 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 06:40:50,571 [trainer.py] => get_original_backbone: True
2025-11-27 06:40:50,571 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 06:40:50,571 [trainer.py] => seed: 0
2025-11-27 06:40:50,571 [trainer.py] => tuned_epoch: 10
2025-11-27 06:40:50,572 [trainer.py] => init_lr: 0.001
2025-11-27 06:40:50,572 [trainer.py] => cpt_first_lr: 0.001
2025-11-27 06:40:50,572 [trainer.py] => cpt_first_epochs: 20
2025-11-27 06:40:50,572 [trainer.py] => cpt_meta_lr: 0.001
2025-11-27 06:40:50,572 [trainer.py] => cpt_meta_epochs: 10
2025-11-27 06:40:50,572 [trainer.py] => batch_size: 16
2025-11-27 06:40:50,572 [trainer.py] => weight_decay: 0.0
2025-11-27 06:40:50,572 [trainer.py] => min_lr: 1e-05
2025-11-27 06:40:50,573 [trainer.py] => optimizer: adam
2025-11-27 06:40:50,573 [trainer.py] => scheduler: constant
2025-11-27 06:40:50,573 [trainer.py] => reinit_optimizer: True
2025-11-27 06:40:50,573 [trainer.py] => global_pool: token
2025-11-27 06:40:50,573 [trainer.py] => head_type: prompt
2025-11-27 06:40:50,573 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2025-11-27 06:40:50,573 [trainer.py] => pretrained: True
2025-11-27 06:40:50,573 [trainer.py] => drop: 0.0
2025-11-27 06:40:50,573 [trainer.py] => drop_path: 0.0
2025-11-27 06:40:50,573 [trainer.py] => prompt_pool: True
2025-11-27 06:40:50,573 [trainer.py] => size: 10
2025-11-27 06:40:50,573 [trainer.py] => length: 5
2025-11-27 06:40:50,573 [trainer.py] => top_k: 5
2025-11-27 06:40:50,573 [trainer.py] => initializer: uniform
2025-11-27 06:40:50,573 [trainer.py] => prompt_key: True
2025-11-27 06:40:50,573 [trainer.py] => prompt_key_init: uniform
2025-11-27 06:40:50,573 [trainer.py] => use_prompt_mask: False
2025-11-27 06:40:50,573 [trainer.py] => shared_prompt_pool: False
2025-11-27 06:40:50,573 [trainer.py] => shared_prompt_key: False
2025-11-27 06:40:50,573 [trainer.py] => batchwise_prompt: True
2025-11-27 06:40:50,573 [trainer.py] => embedding_key: cls
2025-11-27 06:40:50,573 [trainer.py] => predefined_key: 
2025-11-27 06:40:50,573 [trainer.py] => pull_constraint: True
2025-11-27 06:40:50,574 [trainer.py] => pull_constraint_coeff: 0.1
2025-11-27 06:40:50,574 [trainer.py] => mask_old_classes: False
2025-11-27 06:40:52,441 [data_manager.py] => [26, 86, 2, 55, 75, 93, 16, 73, 54, 95, 53, 92, 78, 13, 7, 30, 22, 24, 33, 8, 43, 62, 3, 71, 45, 48, 6, 99, 82, 76, 60, 80, 90, 68, 51, 27, 18, 56, 63, 74, 1, 61, 42, 41, 4, 15, 17, 40, 38, 5, 91, 59, 0, 34, 28, 50, 11, 35, 23, 52, 10, 31, 66, 57, 79, 85, 32, 84, 14, 89, 19, 29, 49, 97, 98, 69, 20, 94, 72, 77, 25, 37, 81, 46, 39, 65, 58, 12, 88, 70, 87, 36, 21, 83, 9, 96, 67, 64, 47, 44]
2025-11-27 06:40:54,456 [vit_cpt.py] => Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 222, 768])
2025-11-27 06:40:54,456 [vit_cpt.py] => Position embedding grid-size from [14, 14] to (14, 14)
2025-11-27 06:40:54,474 [vit_cpt.py] => Successfully loaded pretrained NPZ weights for vit_base_patch16_224_cpt from /root/.cache/torch/hub/checkpoints/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz
2025-11-27 06:40:55,552 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-11-27 06:40:55,880 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 06:40:56,053 [_builder.py] => Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
2025-11-27 06:40:56,072 [cpt.py] => 85,948,516 model total parameters.
2025-11-27 06:40:56,072 [cpt.py] => 130,660 model training parameters.
2025-11-27 06:40:56,073 [cpt.py] => prompt.first_prompt: 3840
2025-11-27 06:40:56,073 [cpt.py] => prompt.prompt: 38400
2025-11-27 06:40:56,073 [cpt.py] => prompt.meta_prompt: 3840
2025-11-27 06:40:56,073 [cpt.py] => prompt.prompt_key: 7680
2025-11-27 06:40:56,073 [cpt.py] => head.weight: 76800
2025-11-27 06:40:56,073 [cpt.py] => head.bias: 100
2025-11-27 06:40:56,075 [trainer.py] => All params: 171824072
2025-11-27 06:40:56,076 [trainer.py] => Trainable params: 130660
2025-11-27 06:40:56,076 [cpt.py] => Learning on 0-10
2025-11-27 06:40:57,168 [cpt.py] => Training first_prompt for task 0
2025-11-27 06:52:08,014 [trainer.py] => config: exps/cpt_c100.json
2025-11-27 06:52:08,015 [trainer.py] => prefix: reproduce
2025-11-27 06:52:08,015 [trainer.py] => dataset: cifar224
2025-11-27 06:52:08,015 [trainer.py] => memory_size: 0
2025-11-27 06:52:08,015 [trainer.py] => memory_per_class: 0
2025-11-27 06:52:08,015 [trainer.py] => fixed_memory: False
2025-11-27 06:52:08,015 [trainer.py] => shuffle: True
2025-11-27 06:52:08,015 [trainer.py] => init_cls: 10
2025-11-27 06:52:08,015 [trainer.py] => increment: 10
2025-11-27 06:52:08,015 [trainer.py] => model_name: cpt
2025-11-27 06:52:08,015 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 06:52:08,015 [trainer.py] => get_original_backbone: True
2025-11-27 06:52:08,015 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 06:52:08,016 [trainer.py] => seed: 0
2025-11-27 06:52:08,016 [trainer.py] => tuned_epoch: 10
2025-11-27 06:52:08,016 [trainer.py] => init_lr: 0.001
2025-11-27 06:52:08,016 [trainer.py] => cpt_first_lr: 0.001
2025-11-27 06:52:08,016 [trainer.py] => cpt_first_epochs: 20
2025-11-27 06:52:08,016 [trainer.py] => cpt_meta_lr: 0.001
2025-11-27 06:52:08,016 [trainer.py] => cpt_meta_epochs: 10
2025-11-27 06:52:08,016 [trainer.py] => batch_size: 16
2025-11-27 06:52:08,016 [trainer.py] => weight_decay: 0.0
2025-11-27 06:52:08,016 [trainer.py] => min_lr: 1e-05
2025-11-27 06:52:08,016 [trainer.py] => optimizer: adam
2025-11-27 06:52:08,016 [trainer.py] => scheduler: constant
2025-11-27 06:52:08,016 [trainer.py] => reinit_optimizer: True
2025-11-27 06:52:08,016 [trainer.py] => global_pool: token
2025-11-27 06:52:08,016 [trainer.py] => head_type: prompt
2025-11-27 06:52:08,016 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2025-11-27 06:52:08,016 [trainer.py] => pretrained: True
2025-11-27 06:52:08,016 [trainer.py] => drop: 0.0
2025-11-27 06:52:08,016 [trainer.py] => drop_path: 0.0
2025-11-27 06:52:08,016 [trainer.py] => prompt_pool: True
2025-11-27 06:52:08,016 [trainer.py] => size: 10
2025-11-27 06:52:08,016 [trainer.py] => length: 5
2025-11-27 06:52:08,016 [trainer.py] => top_k: 5
2025-11-27 06:52:08,017 [trainer.py] => initializer: uniform
2025-11-27 06:52:08,017 [trainer.py] => prompt_key: True
2025-11-27 06:52:08,017 [trainer.py] => prompt_key_init: uniform
2025-11-27 06:52:08,017 [trainer.py] => use_prompt_mask: False
2025-11-27 06:52:08,017 [trainer.py] => shared_prompt_pool: False
2025-11-27 06:52:08,017 [trainer.py] => shared_prompt_key: False
2025-11-27 06:52:08,017 [trainer.py] => batchwise_prompt: True
2025-11-27 06:52:08,017 [trainer.py] => embedding_key: cls
2025-11-27 06:52:08,017 [trainer.py] => predefined_key: 
2025-11-27 06:52:08,017 [trainer.py] => pull_constraint: True
2025-11-27 06:52:08,017 [trainer.py] => pull_constraint_coeff: 0.1
2025-11-27 06:52:08,017 [trainer.py] => mask_old_classes: False
2025-11-27 06:52:10,047 [data_manager.py] => [26, 86, 2, 55, 75, 93, 16, 73, 54, 95, 53, 92, 78, 13, 7, 30, 22, 24, 33, 8, 43, 62, 3, 71, 45, 48, 6, 99, 82, 76, 60, 80, 90, 68, 51, 27, 18, 56, 63, 74, 1, 61, 42, 41, 4, 15, 17, 40, 38, 5, 91, 59, 0, 34, 28, 50, 11, 35, 23, 52, 10, 31, 66, 57, 79, 85, 32, 84, 14, 89, 19, 29, 49, 97, 98, 69, 20, 94, 72, 77, 25, 37, 81, 46, 39, 65, 58, 12, 88, 70, 87, 36, 21, 83, 9, 96, 67, 64, 47, 44]
2025-11-27 06:52:12,290 [vit_cpt.py] => Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 222, 768])
2025-11-27 06:52:12,291 [vit_cpt.py] => Position embedding grid-size from [14, 14] to (14, 14)
2025-11-27 06:52:12,300 [vit_cpt.py] => Successfully loaded pretrained NPZ weights for vit_base_patch16_224_cpt from /root/.cache/torch/hub/checkpoints/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz
2025-11-27 06:54:54,655 [trainer.py] => config: exps/cpt_c100.json
2025-11-27 06:54:54,657 [trainer.py] => prefix: reproduce
2025-11-27 06:54:54,657 [trainer.py] => dataset: cifar224
2025-11-27 06:54:54,657 [trainer.py] => memory_size: 0
2025-11-27 06:54:54,657 [trainer.py] => memory_per_class: 0
2025-11-27 06:54:54,657 [trainer.py] => fixed_memory: False
2025-11-27 06:54:54,657 [trainer.py] => shuffle: True
2025-11-27 06:54:54,658 [trainer.py] => init_cls: 10
2025-11-27 06:54:54,658 [trainer.py] => increment: 10
2025-11-27 06:54:54,658 [trainer.py] => model_name: cpt
2025-11-27 06:54:54,658 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 06:54:54,658 [trainer.py] => get_original_backbone: True
2025-11-27 06:54:54,658 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 06:54:54,658 [trainer.py] => seed: 0
2025-11-27 06:54:54,658 [trainer.py] => tuned_epoch: 10
2025-11-27 06:54:54,658 [trainer.py] => init_lr: 0.001
2025-11-27 06:54:54,658 [trainer.py] => cpt_first_lr: 0.001
2025-11-27 06:54:54,658 [trainer.py] => cpt_first_epochs: 20
2025-11-27 06:54:54,658 [trainer.py] => cpt_meta_lr: 0.001
2025-11-27 06:54:54,658 [trainer.py] => cpt_meta_epochs: 10
2025-11-27 06:54:54,658 [trainer.py] => batch_size: 16
2025-11-27 06:54:54,659 [trainer.py] => weight_decay: 0.0
2025-11-27 06:54:54,659 [trainer.py] => min_lr: 1e-05
2025-11-27 06:54:54,659 [trainer.py] => optimizer: adam
2025-11-27 06:54:54,659 [trainer.py] => scheduler: constant
2025-11-27 06:54:54,659 [trainer.py] => reinit_optimizer: True
2025-11-27 06:54:54,659 [trainer.py] => global_pool: token
2025-11-27 06:54:54,659 [trainer.py] => head_type: prompt
2025-11-27 06:54:54,659 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2025-11-27 06:54:54,659 [trainer.py] => pretrained: True
2025-11-27 06:54:54,659 [trainer.py] => drop: 0.0
2025-11-27 06:54:54,659 [trainer.py] => drop_path: 0.0
2025-11-27 06:54:54,659 [trainer.py] => prompt_pool: True
2025-11-27 06:54:54,659 [trainer.py] => size: 10
2025-11-27 06:54:54,659 [trainer.py] => length: 5
2025-11-27 06:54:54,659 [trainer.py] => top_k: 5
2025-11-27 06:54:54,659 [trainer.py] => initializer: uniform
2025-11-27 06:54:54,659 [trainer.py] => prompt_key: True
2025-11-27 06:54:54,659 [trainer.py] => prompt_key_init: uniform
2025-11-27 06:54:54,659 [trainer.py] => use_prompt_mask: False
2025-11-27 06:54:54,659 [trainer.py] => shared_prompt_pool: False
2025-11-27 06:54:54,659 [trainer.py] => shared_prompt_key: False
2025-11-27 06:54:54,659 [trainer.py] => batchwise_prompt: True
2025-11-27 06:54:54,659 [trainer.py] => embedding_key: cls
2025-11-27 06:54:54,660 [trainer.py] => predefined_key: 
2025-11-27 06:54:54,660 [trainer.py] => pull_constraint: True
2025-11-27 06:54:54,660 [trainer.py] => pull_constraint_coeff: 0.1
2025-11-27 06:54:54,660 [trainer.py] => mask_old_classes: False
2025-11-27 06:54:56,660 [data_manager.py] => [26, 86, 2, 55, 75, 93, 16, 73, 54, 95, 53, 92, 78, 13, 7, 30, 22, 24, 33, 8, 43, 62, 3, 71, 45, 48, 6, 99, 82, 76, 60, 80, 90, 68, 51, 27, 18, 56, 63, 74, 1, 61, 42, 41, 4, 15, 17, 40, 38, 5, 91, 59, 0, 34, 28, 50, 11, 35, 23, 52, 10, 31, 66, 57, 79, 85, 32, 84, 14, 89, 19, 29, 49, 97, 98, 69, 20, 94, 72, 77, 25, 37, 81, 46, 39, 65, 58, 12, 88, 70, 87, 36, 21, 83, 9, 96, 67, 64, 47, 44]
2025-11-27 06:54:58,525 [vit_cpt.py] => Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 222, 768])
2025-11-27 06:54:58,527 [vit_cpt.py] => Position embedding grid-size from [14, 14] to (14, 14)
2025-11-27 06:54:58,531 [vit_cpt.py] => Successfully loaded pretrained NPZ weights for vit_base_patch16_224_cpt from /root/.cache/torch/hub/checkpoints/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz
2025-11-27 06:54:58,532 [cpt.py] => 85,948,516 model total parameters.
2025-11-27 06:54:58,533 [cpt.py] => 130,660 model training parameters.
2025-11-27 06:54:58,533 [cpt.py] => prompt.first_prompt: 3840
2025-11-27 06:54:58,533 [cpt.py] => prompt.prompt: 38400
2025-11-27 06:54:58,533 [cpt.py] => prompt.meta_prompt: 3840
2025-11-27 06:54:58,533 [cpt.py] => prompt.prompt_key: 7680
2025-11-27 06:54:58,533 [cpt.py] => head.weight: 76800
2025-11-27 06:54:58,533 [cpt.py] => head.bias: 100
2025-11-27 06:54:58,534 [trainer.py] => All params: 85948516
2025-11-27 06:54:58,535 [trainer.py] => Trainable params: 130660
2025-11-27 06:54:58,535 [cpt.py] => Learning on 0-10
2025-11-27 06:54:59,385 [cpt.py] => Training first_prompt for task 0
2025-11-27 07:06:04,741 [cpt.py] => Task 0, Epoch 20/20 => Loss 1.972, Train_accy 29.10, Test_accy 24.70
2025-11-27 07:06:08,448 [trainer.py] => No NME accuracy.
2025-11-27 07:06:08,448 [trainer.py] => CNN: {'total': np.float64(24.7), '00-09': np.float64(24.7), 'old': 0, 'new': np.float64(24.7)}
2025-11-27 07:06:08,449 [trainer.py] => CNN top1 curve: [np.float64(24.7)]
2025-11-27 07:06:08,449 [trainer.py] => CNN top5 curve: [np.float64(76.9)]

2025-11-27 07:06:08,449 [trainer.py] => Average Accuracy (CNN): 24.7 

2025-11-27 07:06:08,450 [trainer.py] => All params: 85948516
2025-11-27 07:06:08,451 [trainer.py] => Trainable params: 130660
2025-11-27 07:06:08,451 [cpt.py] => Learning on 10-20
2025-11-27 07:06:08,553 [cpt.py] => Training prompt for task 1
2025-11-27 07:40:29,812 [trainer.py] => config: exps/cpt_c100.json
2025-11-27 07:40:29,813 [trainer.py] => prefix: reproduce
2025-11-27 07:40:29,813 [trainer.py] => dataset: cifar224
2025-11-27 07:40:29,813 [trainer.py] => memory_size: 0
2025-11-27 07:40:29,813 [trainer.py] => memory_per_class: 0
2025-11-27 07:40:29,813 [trainer.py] => fixed_memory: False
2025-11-27 07:40:29,813 [trainer.py] => shuffle: True
2025-11-27 07:40:29,813 [trainer.py] => init_cls: 10
2025-11-27 07:40:29,813 [trainer.py] => increment: 10
2025-11-27 07:40:29,813 [trainer.py] => model_name: cpt
2025-11-27 07:40:29,813 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 07:40:29,813 [trainer.py] => get_original_backbone: True
2025-11-27 07:40:29,813 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 07:40:29,813 [trainer.py] => seed: 0
2025-11-27 07:40:29,813 [trainer.py] => tuned_epoch: 10
2025-11-27 07:40:29,813 [trainer.py] => init_lr: 0.001
2025-11-27 07:40:29,813 [trainer.py] => cpt_first_lr: 0.001
2025-11-27 07:40:29,813 [trainer.py] => cpt_first_epochs: 20
2025-11-27 07:40:29,813 [trainer.py] => cpt_meta_lr: 0.001
2025-11-27 07:40:29,813 [trainer.py] => cpt_meta_epochs: 10
2025-11-27 07:40:29,813 [trainer.py] => batch_size: 16
2025-11-27 07:40:29,813 [trainer.py] => weight_decay: 0.0
2025-11-27 07:40:29,814 [trainer.py] => min_lr: 1e-05
2025-11-27 07:40:29,814 [trainer.py] => optimizer: adam
2025-11-27 07:40:29,814 [trainer.py] => scheduler: constant
2025-11-27 07:40:29,814 [trainer.py] => reinit_optimizer: True
2025-11-27 07:40:29,814 [trainer.py] => global_pool: token
2025-11-27 07:40:29,814 [trainer.py] => head_type: prompt
2025-11-27 07:40:29,814 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2025-11-27 07:40:29,814 [trainer.py] => pretrained: True
2025-11-27 07:40:29,814 [trainer.py] => drop: 0.0
2025-11-27 07:40:29,814 [trainer.py] => drop_path: 0.0
2025-11-27 07:40:29,814 [trainer.py] => prompt_pool: True
2025-11-27 07:40:29,814 [trainer.py] => size: 10
2025-11-27 07:40:29,814 [trainer.py] => length: 5
2025-11-27 07:40:29,814 [trainer.py] => top_k: 5
2025-11-27 07:40:29,814 [trainer.py] => initializer: uniform
2025-11-27 07:40:29,814 [trainer.py] => prompt_key: True
2025-11-27 07:40:29,815 [trainer.py] => prompt_key_init: uniform
2025-11-27 07:40:29,815 [trainer.py] => use_prompt_mask: False
2025-11-27 07:40:29,815 [trainer.py] => shared_prompt_pool: False
2025-11-27 07:40:29,815 [trainer.py] => shared_prompt_key: False
2025-11-27 07:40:29,815 [trainer.py] => batchwise_prompt: True
2025-11-27 07:40:29,815 [trainer.py] => embedding_key: cls
2025-11-27 07:40:29,815 [trainer.py] => predefined_key: 
2025-11-27 07:40:29,815 [trainer.py] => pull_constraint: True
2025-11-27 07:40:29,815 [trainer.py] => pull_constraint_coeff: 0.1
2025-11-27 07:40:29,815 [trainer.py] => mask_old_classes: False
2025-11-27 07:40:31,723 [data_manager.py] => [26, 86, 2, 55, 75, 93, 16, 73, 54, 95, 53, 92, 78, 13, 7, 30, 22, 24, 33, 8, 43, 62, 3, 71, 45, 48, 6, 99, 82, 76, 60, 80, 90, 68, 51, 27, 18, 56, 63, 74, 1, 61, 42, 41, 4, 15, 17, 40, 38, 5, 91, 59, 0, 34, 28, 50, 11, 35, 23, 52, 10, 31, 66, 57, 79, 85, 32, 84, 14, 89, 19, 29, 49, 97, 98, 69, 20, 94, 72, 77, 25, 37, 81, 46, 39, 65, 58, 12, 88, 70, 87, 36, 21, 83, 9, 96, 67, 64, 47, 44]
2025-11-27 07:40:33,804 [vit_cpt.py] => Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 222, 768])
2025-11-27 07:40:33,805 [vit_cpt.py] => Position embedding grid-size from [14, 14] to (14, 14)
2025-11-27 07:40:33,807 [vit_cpt.py] => Successfully loaded pretrained NPZ weights for vit_base_patch16_224_cpt from /root/.cache/torch/hub/checkpoints/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_224.npz
2025-11-27 07:40:34,904 [vit_cpt.py] => Loaded NPZ weights for vit_base_patch16_224 from /root/.cache/torch/hub/checkpoints/ViT-B_16.npz
2025-11-27 07:40:34,908 [cpt.py] => 85,948,516 model total parameters.
2025-11-27 07:40:34,909 [cpt.py] => 130,660 model training parameters.
2025-11-27 07:40:34,909 [cpt.py] => prompt.first_prompt: 3840
2025-11-27 07:40:34,909 [cpt.py] => prompt.prompt: 38400
2025-11-27 07:40:34,909 [cpt.py] => prompt.meta_prompt: 3840
2025-11-27 07:40:34,909 [cpt.py] => prompt.prompt_key: 7680
2025-11-27 07:40:34,909 [cpt.py] => head.weight: 76800
2025-11-27 07:40:34,909 [cpt.py] => head.bias: 100
2025-11-27 07:40:34,911 [trainer.py] => All params: 171824072
2025-11-27 07:40:34,912 [trainer.py] => Trainable params: 130660
2025-11-27 07:40:34,912 [cpt.py] => Learning on 0-10
2025-11-27 07:40:36,067 [cpt.py] => Training first_prompt for task 0
2025-11-27 07:56:41,719 [cpt.py] => Task 0, Epoch 20/20 => Loss 1.972, Train_accy 29.64, Test_accy 26.70
2025-11-27 07:56:48,420 [trainer.py] => No NME accuracy.
2025-11-27 07:56:48,421 [trainer.py] => CNN: {'total': np.float64(26.7), '00-09': np.float64(26.7), 'old': 0, 'new': np.float64(26.7)}
2025-11-27 07:56:48,421 [trainer.py] => CNN top1 curve: [np.float64(26.7)]
2025-11-27 07:56:48,422 [trainer.py] => CNN top5 curve: [np.float64(77.0)]

2025-11-27 07:56:48,422 [trainer.py] => Average Accuracy (CNN): 26.7 

2025-11-27 07:56:48,426 [trainer.py] => All params: 171824072
2025-11-27 07:56:48,427 [trainer.py] => Trainable params: 130660
2025-11-27 07:56:48,427 [cpt.py] => Learning on 10-20
2025-11-27 07:56:48,492 [cpt.py] => Training prompt for task 1
