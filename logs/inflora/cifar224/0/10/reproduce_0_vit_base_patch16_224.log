2025-11-23 18:29:13,724 [trainer.py] => config: exps/inflora_c100.json
2025-11-23 18:29:13,725 [trainer.py] => prefix: reproduce
2025-11-23 18:29:13,725 [trainer.py] => dataset: cifar224
2025-11-23 18:29:13,725 [trainer.py] => memory_size: 0
2025-11-23 18:29:13,725 [trainer.py] => memory_per_class: 0
2025-11-23 18:29:13,725 [trainer.py] => fixed_memory: True
2025-11-23 18:29:13,725 [trainer.py] => shuffle: False
2025-11-23 18:29:13,726 [trainer.py] => init_cls: 10
2025-11-23 18:29:13,726 [trainer.py] => increment: 10
2025-11-23 18:29:13,726 [trainer.py] => model_name: inflora
2025-11-23 18:29:13,726 [trainer.py] => net_type: sip
2025-11-23 18:29:13,726 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-23 18:29:13,726 [trainer.py] => pretrained: True
2025-11-23 18:29:13,726 [trainer.py] => embd_dim: 768
2025-11-23 18:29:13,726 [trainer.py] => num_heads: 12
2025-11-23 18:29:13,726 [trainer.py] => total_sessions: 10
2025-11-23 18:29:13,726 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-23 18:29:13,726 [trainer.py] => seed: 0
2025-11-23 18:29:13,726 [trainer.py] => EPSILON: 1e-08
2025-11-23 18:29:13,726 [trainer.py] => optim: adam
2025-11-23 18:29:13,726 [trainer.py] => init_epoch: 20
2025-11-23 18:29:13,727 [trainer.py] => init_lr: 0.0005
2025-11-23 18:29:13,727 [trainer.py] => init_lr_decay: 0.1
2025-11-23 18:29:13,727 [trainer.py] => init_weight_decay: 0.0
2025-11-23 18:29:13,727 [trainer.py] => epochs: 20
2025-11-23 18:29:13,727 [trainer.py] => lrate: 0.0005
2025-11-23 18:29:13,727 [trainer.py] => lrate_decay: 0.1
2025-11-23 18:29:13,727 [trainer.py] => batch_size: 128
2025-11-23 18:29:13,727 [trainer.py] => weight_decay: 0.0
2025-11-23 18:29:13,727 [trainer.py] => rank: 10
2025-11-23 18:29:13,727 [trainer.py] => lamb: 0.95
2025-11-23 18:29:13,727 [trainer.py] => lame: 1.0
2025-11-23 18:29:13,727 [trainer.py] => num_workers: 8
2025-11-23 18:29:15,924 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2025-11-23 18:29:19,369 [sinet_inflora.py] => Using vit_base_patch16_224_in21k instead of vit_base_patch16_224 for better pretrained weights
2025-11-23 18:29:19,370 [sinet_inflora.py] => Creating SiNet with variant=vit_base_patch16_224_in21k, pretrained=True
2025-11-23 18:29:20,963 [sinet_inflora.py] => Loading pretrained weights for vit_base_patch16_224_in21k using timm...
2025-11-23 18:29:22,155 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-11-23 18:29:22,776 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-23 18:29:23,280 [sinet_inflora.py] => Successfully loaded using direct import from timm.models.vision_transformer
2025-11-23 18:29:23,398 [sinet_inflora.py] => Missing keys (non-LoRA): ['cls_token_grow', 'pos_embed_grow', 'head.weight', 'head.bias']...
2025-11-23 18:29:23,399 [sinet_inflora.py] => Successfully loaded 150/150 pretrained weights for vit_base_patch16_224_in21k
2025-11-23 18:29:23,420 [trainer.py] => All params: 111194651
2025-11-23 18:29:23,422 [trainer.py] => Trainable params: 111194651
2025-11-23 18:29:23,423 [inflora.py] => Learning on 0-10
2025-11-23 18:29:49,867 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight'}
2025-11-23 18:41:54,222 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.146, Train_accy 94.76
2025-11-23 18:42:13,510 [inflora.py] => Threshold: 0.95
2025-11-23 18:42:21,328 [inflora.py] => ----------------------------------------
2025-11-23 18:42:21,329 [inflora.py] => Gradient Constraints Summary
2025-11-23 18:42:21,330 [inflora.py] => ----------------------------------------
2025-11-23 18:42:21,330 [inflora.py] => 1 layer constraint size: 6
2025-11-23 18:42:21,330 [inflora.py] => 2 layer constraint size: 9
2025-11-23 18:42:21,330 [inflora.py] => 3 layer constraint size: 11
2025-11-23 18:42:21,330 [inflora.py] => 4 layer constraint size: 10
2025-11-23 18:42:21,330 [inflora.py] => 5 layer constraint size: 13
2025-11-23 18:42:21,330 [inflora.py] => 6 layer constraint size: 15
2025-11-23 18:42:21,330 [inflora.py] => 7 layer constraint size: 13
2025-11-23 18:42:21,330 [inflora.py] => 8 layer constraint size: 16
2025-11-23 18:42:21,331 [inflora.py] => 9 layer constraint size: 19
2025-11-23 18:42:21,331 [inflora.py] => 10 layer constraint size: 17
2025-11-23 18:42:21,331 [inflora.py] => 11 layer constraint size: 6
2025-11-23 18:42:21,331 [inflora.py] => 12 layer constraint size: 11
2025-11-27 13:05:47,531 [trainer.py] => config: exps/inflora_c100.json
2025-11-27 13:05:47,532 [trainer.py] => prefix: reproduce
2025-11-27 13:05:47,532 [trainer.py] => dataset: cifar224
2025-11-27 13:05:47,532 [trainer.py] => memory_size: 0
2025-11-27 13:05:47,532 [trainer.py] => memory_per_class: 0
2025-11-27 13:05:47,532 [trainer.py] => fixed_memory: True
2025-11-27 13:05:47,532 [trainer.py] => shuffle: False
2025-11-27 13:05:47,532 [trainer.py] => init_cls: 10
2025-11-27 13:05:47,532 [trainer.py] => increment: 10
2025-11-27 13:05:47,532 [trainer.py] => model_name: inflora
2025-11-27 13:05:47,532 [trainer.py] => net_type: sip
2025-11-27 13:05:47,532 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 13:05:47,532 [trainer.py] => pretrained: True
2025-11-27 13:05:47,532 [trainer.py] => embd_dim: 768
2025-11-27 13:05:47,532 [trainer.py] => num_heads: 12
2025-11-27 13:05:47,533 [trainer.py] => total_sessions: 10
2025-11-27 13:05:47,533 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 13:05:47,533 [trainer.py] => seed: 0
2025-11-27 13:05:47,533 [trainer.py] => EPSILON: 1e-08
2025-11-27 13:05:47,533 [trainer.py] => optim: adam
2025-11-27 13:05:47,533 [trainer.py] => init_epoch: 20
2025-11-27 13:05:47,533 [trainer.py] => init_lr: 0.0005
2025-11-27 13:05:47,533 [trainer.py] => init_lr_decay: 0.1
2025-11-27 13:05:47,533 [trainer.py] => init_weight_decay: 0.0
2025-11-27 13:05:47,533 [trainer.py] => epochs: 20
2025-11-27 13:05:47,533 [trainer.py] => lrate: 0.0005
2025-11-27 13:05:47,533 [trainer.py] => lrate_decay: 0.1
2025-11-27 13:05:47,533 [trainer.py] => batch_size: 128
2025-11-27 13:05:47,533 [trainer.py] => weight_decay: 0.0
2025-11-27 13:05:47,533 [trainer.py] => rank: 10
2025-11-27 13:05:47,533 [trainer.py] => lamb: 0.95
2025-11-27 13:05:47,533 [trainer.py] => lame: 1.0
2025-11-27 13:05:47,533 [trainer.py] => num_workers: 8
2025-11-27 13:05:49,578 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2025-11-27 13:05:59,677 [sinet_inflora.py] => Using vit_base_patch16_224_in21k instead of vit_base_patch16_224 for better pretrained weights
2025-11-27 13:05:59,677 [sinet_inflora.py] => Creating SiNet with variant=vit_base_patch16_224_in21k, pretrained=True
2025-11-27 13:06:01,785 [sinet_inflora.py] => Loading pretrained weights for vit_base_patch16_224_in21k using timm...
2025-11-27 13:06:02,986 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-11-27 13:06:03,494 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 13:06:09,141 [sinet_inflora.py] => Successfully loaded using direct import from timm.models.vision_transformer
2025-11-27 13:06:09,211 [sinet_inflora.py] => Missing keys (non-LoRA): ['cls_token_grow', 'pos_embed_grow', 'head.weight', 'head.bias']...
2025-11-27 13:06:09,211 [sinet_inflora.py] => Successfully loaded 150/150 pretrained weights for vit_base_patch16_224_in21k
2025-11-27 13:06:09,243 [trainer.py] => All params: 111194651
2025-11-27 13:06:09,245 [trainer.py] => Trainable params: 111194651
2025-11-27 13:06:09,245 [inflora.py] => Learning on 0-10
2025-11-27 13:06:33,037 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight'}
2025-11-27 13:18:02,433 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.146, Train_accy 94.76
2025-11-27 13:18:19,953 [inflora.py] => Threshold: 0.95
2025-11-27 13:18:23,007 [inflora.py] => ----------------------------------------
2025-11-27 13:18:23,007 [inflora.py] => Gradient Constraints Summary
2025-11-27 13:18:23,008 [inflora.py] => ----------------------------------------
2025-11-27 13:18:23,008 [inflora.py] => 1 layer constraint size: 6
2025-11-27 13:18:23,008 [inflora.py] => 2 layer constraint size: 9
2025-11-27 13:18:23,008 [inflora.py] => 3 layer constraint size: 11
2025-11-27 13:18:23,008 [inflora.py] => 4 layer constraint size: 10
2025-11-27 13:18:23,008 [inflora.py] => 5 layer constraint size: 13
2025-11-27 13:18:23,008 [inflora.py] => 6 layer constraint size: 15
2025-11-27 13:18:23,008 [inflora.py] => 7 layer constraint size: 13
2025-11-27 13:18:23,008 [inflora.py] => 8 layer constraint size: 16
2025-11-27 13:18:23,008 [inflora.py] => 9 layer constraint size: 19
2025-11-27 13:18:23,008 [inflora.py] => 10 layer constraint size: 17
2025-11-27 13:18:23,008 [inflora.py] => 11 layer constraint size: 6
2025-11-27 13:18:23,008 [inflora.py] => 12 layer constraint size: 11
2025-11-27 13:43:09,672 [trainer.py] => config: exps/inflora_c100.json
2025-11-27 13:43:09,673 [trainer.py] => prefix: reproduce
2025-11-27 13:43:09,673 [trainer.py] => dataset: cifar224
2025-11-27 13:43:09,673 [trainer.py] => memory_size: 0
2025-11-27 13:43:09,673 [trainer.py] => memory_per_class: 0
2025-11-27 13:43:09,673 [trainer.py] => fixed_memory: True
2025-11-27 13:43:09,673 [trainer.py] => shuffle: False
2025-11-27 13:43:09,673 [trainer.py] => init_cls: 10
2025-11-27 13:43:09,673 [trainer.py] => increment: 10
2025-11-27 13:43:09,673 [trainer.py] => model_name: inflora
2025-11-27 13:43:09,673 [trainer.py] => net_type: sip
2025-11-27 13:43:09,673 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 13:43:09,674 [trainer.py] => pretrained: True
2025-11-27 13:43:09,674 [trainer.py] => embd_dim: 768
2025-11-27 13:43:09,674 [trainer.py] => num_heads: 12
2025-11-27 13:43:09,674 [trainer.py] => total_sessions: 10
2025-11-27 13:43:09,674 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 13:43:09,674 [trainer.py] => seed: 0
2025-11-27 13:43:09,674 [trainer.py] => EPSILON: 1e-08
2025-11-27 13:43:09,674 [trainer.py] => optim: adam
2025-11-27 13:43:09,674 [trainer.py] => init_epoch: 20
2025-11-27 13:43:09,674 [trainer.py] => init_lr: 0.0005
2025-11-27 13:43:09,674 [trainer.py] => init_lr_decay: 0.1
2025-11-27 13:43:09,674 [trainer.py] => init_weight_decay: 0.0
2025-11-27 13:43:09,675 [trainer.py] => epochs: 20
2025-11-27 13:43:09,675 [trainer.py] => lrate: 0.0005
2025-11-27 13:43:09,675 [trainer.py] => lrate_decay: 0.1
2025-11-27 13:43:09,675 [trainer.py] => batch_size: 128
2025-11-27 13:43:09,675 [trainer.py] => weight_decay: 0.0
2025-11-27 13:43:09,675 [trainer.py] => rank: 10
2025-11-27 13:43:09,675 [trainer.py] => lamb: 0.95
2025-11-27 13:43:09,675 [trainer.py] => lame: 1.0
2025-11-27 13:43:09,675 [trainer.py] => num_workers: 8
2025-11-27 13:43:11,811 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2025-11-27 13:43:15,493 [sinet_inflora.py] => Using vit_base_patch16_224_in21k instead of vit_base_patch16_224 for better pretrained weights
2025-11-27 13:43:15,493 [sinet_inflora.py] => Creating SiNet with variant=vit_base_patch16_224_in21k, pretrained=True
2025-11-27 13:43:17,081 [sinet_inflora.py] => Loading pretrained weights for vit_base_patch16_224_in21k using timm...
2025-11-27 13:43:18,204 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-11-27 13:43:18,992 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 13:43:19,744 [sinet_inflora.py] => Successfully loaded using direct import from timm.models.vision_transformer
2025-11-27 13:43:19,817 [sinet_inflora.py] => Missing keys (non-LoRA): ['cls_token_grow', 'pos_embed_grow', 'head.weight', 'head.bias']...
2025-11-27 13:43:19,817 [sinet_inflora.py] => Successfully loaded 150/150 pretrained weights for vit_base_patch16_224_in21k
2025-11-27 13:43:19,842 [trainer.py] => All params: 111194651
2025-11-27 13:43:19,844 [trainer.py] => Trainable params: 111194651
2025-11-27 13:43:19,844 [inflora.py] => Learning on 0-10
2025-11-27 13:43:44,611 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight'}
2025-11-27 13:55:11,130 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.146, Train_accy 94.76
2025-11-27 13:55:29,045 [inflora.py] => Threshold: 0.95
2025-11-27 13:55:32,112 [inflora.py] => ----------------------------------------
2025-11-27 13:55:32,113 [inflora.py] => Gradient Constraints Summary
2025-11-27 13:55:32,113 [inflora.py] => ----------------------------------------
2025-11-27 13:55:32,113 [inflora.py] => 1 layer constraint size: 6
2025-11-27 13:55:32,113 [inflora.py] => 2 layer constraint size: 9
2025-11-27 13:55:32,113 [inflora.py] => 3 layer constraint size: 11
2025-11-27 13:55:32,113 [inflora.py] => 4 layer constraint size: 10
2025-11-27 13:55:32,113 [inflora.py] => 5 layer constraint size: 13
2025-11-27 13:55:32,113 [inflora.py] => 6 layer constraint size: 15
2025-11-27 13:55:32,113 [inflora.py] => 7 layer constraint size: 13
2025-11-27 13:55:32,113 [inflora.py] => 8 layer constraint size: 16
2025-11-27 13:55:32,114 [inflora.py] => 9 layer constraint size: 19
2025-11-27 13:55:32,114 [inflora.py] => 10 layer constraint size: 17
2025-11-27 13:55:32,114 [inflora.py] => 11 layer constraint size: 6
2025-11-27 13:55:32,114 [inflora.py] => 12 layer constraint size: 11
2025-11-27 14:03:25,879 [trainer.py] => config: exps/inflora_c100.json
2025-11-27 14:03:25,880 [trainer.py] => prefix: reproduce
2025-11-27 14:03:25,881 [trainer.py] => dataset: cifar224
2025-11-27 14:03:25,881 [trainer.py] => memory_size: 0
2025-11-27 14:03:25,881 [trainer.py] => memory_per_class: 0
2025-11-27 14:03:25,881 [trainer.py] => fixed_memory: True
2025-11-27 14:03:25,881 [trainer.py] => shuffle: False
2025-11-27 14:03:25,881 [trainer.py] => init_cls: 10
2025-11-27 14:03:25,881 [trainer.py] => increment: 10
2025-11-27 14:03:25,881 [trainer.py] => model_name: inflora
2025-11-27 14:03:25,881 [trainer.py] => net_type: sip
2025-11-27 14:03:25,881 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 14:03:25,881 [trainer.py] => pretrained: True
2025-11-27 14:03:25,881 [trainer.py] => embd_dim: 768
2025-11-27 14:03:25,881 [trainer.py] => num_heads: 12
2025-11-27 14:03:25,881 [trainer.py] => total_sessions: 10
2025-11-27 14:03:25,881 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 14:03:25,882 [trainer.py] => seed: 0
2025-11-27 14:03:25,882 [trainer.py] => EPSILON: 1e-08
2025-11-27 14:03:25,882 [trainer.py] => optim: adam
2025-11-27 14:03:25,882 [trainer.py] => init_epoch: 20
2025-11-27 14:03:25,882 [trainer.py] => init_lr: 0.0005
2025-11-27 14:03:25,882 [trainer.py] => init_lr_decay: 0.1
2025-11-27 14:03:25,882 [trainer.py] => init_weight_decay: 0.0
2025-11-27 14:03:25,882 [trainer.py] => epochs: 20
2025-11-27 14:03:25,882 [trainer.py] => lrate: 0.0005
2025-11-27 14:03:25,882 [trainer.py] => lrate_decay: 0.1
2025-11-27 14:03:25,882 [trainer.py] => batch_size: 128
2025-11-27 14:03:25,883 [trainer.py] => weight_decay: 0.0
2025-11-27 14:03:25,883 [trainer.py] => rank: 10
2025-11-27 14:03:25,883 [trainer.py] => lamb: 0.95
2025-11-27 14:03:25,883 [trainer.py] => lame: 1.0
2025-11-27 14:03:25,883 [trainer.py] => num_workers: 8
2025-11-27 14:03:30,849 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2025-11-27 14:03:39,760 [sinet_inflora.py] => Using vit_base_patch16_224_in21k instead of vit_base_patch16_224 for better pretrained weights
2025-11-27 14:03:39,761 [sinet_inflora.py] => Creating SiNet with variant=vit_base_patch16_224_in21k, pretrained=True
2025-11-27 14:03:41,568 [sinet_inflora.py] => Loading pretrained weights for vit_base_patch16_224_in21k using timm...
2025-11-27 14:03:42,910 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-11-27 14:03:43,331 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 14:03:43,754 [sinet_inflora.py] => Successfully loaded using direct import from timm.models.vision_transformer
2025-11-27 14:03:43,779 [sinet_inflora.py] => Missing keys (non-LoRA): ['cls_token_grow', 'pos_embed_grow', 'head.weight', 'head.bias']...
2025-11-27 14:03:43,779 [sinet_inflora.py] => Successfully loaded 150/150 pretrained weights for vit_base_patch16_224_in21k
2025-11-27 14:03:43,801 [trainer.py] => All params: 111194651
2025-11-27 14:03:43,803 [trainer.py] => Trainable params: 111194651
2025-11-27 14:03:43,804 [inflora.py] => Learning on 0-10
2025-11-27 14:04:09,336 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight'}
2025-11-27 14:16:35,302 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.146, Train_accy 94.76
2025-11-27 14:16:53,699 [inflora.py] => Threshold: 0.95
2025-11-27 14:16:57,259 [inflora.py] => ----------------------------------------
2025-11-27 14:16:57,259 [inflora.py] => Gradient Constraints Summary
2025-11-27 14:16:57,259 [inflora.py] => ----------------------------------------
2025-11-27 14:16:57,259 [inflora.py] => 1 layer constraint size: 6
2025-11-27 14:16:57,259 [inflora.py] => 2 layer constraint size: 9
2025-11-27 14:16:57,259 [inflora.py] => 3 layer constraint size: 11
2025-11-27 14:16:57,259 [inflora.py] => 4 layer constraint size: 10
2025-11-27 14:16:57,259 [inflora.py] => 5 layer constraint size: 13
2025-11-27 14:16:57,260 [inflora.py] => 6 layer constraint size: 15
2025-11-27 14:16:57,260 [inflora.py] => 7 layer constraint size: 13
2025-11-27 14:16:57,260 [inflora.py] => 8 layer constraint size: 16
2025-11-27 14:16:57,260 [inflora.py] => 9 layer constraint size: 19
2025-11-27 14:16:57,260 [inflora.py] => 10 layer constraint size: 17
2025-11-27 14:16:57,260 [inflora.py] => 11 layer constraint size: 6
2025-11-27 14:16:57,260 [inflora.py] => 12 layer constraint size: 11
2025-11-27 14:16:57,277 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:16:57,279 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:16:57,284 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:16:57,287 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:16:57,290 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:16:57,292 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:16:57,297 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:16:57,299 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:16:57,300 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:16:57,301 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:16:57,304 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:16:57,306 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:17:18,552 [inflora.py] => Exemplar size: 0
2025-11-27 14:17:18,552 [trainer.py] => No NME accuracy.
2025-11-27 14:17:18,560 [trainer.py] => CNN: {'total': np.float64(99.8), '00-09': np.float64(99.8), 'old': 0, 'new': np.float64(99.8)}
2025-11-27 14:21:19,970 [trainer.py] => config: exps/inflora_c100.json
2025-11-27 14:21:19,971 [trainer.py] => prefix: reproduce
2025-11-27 14:21:19,971 [trainer.py] => dataset: cifar224
2025-11-27 14:21:19,971 [trainer.py] => memory_size: 0
2025-11-27 14:21:19,971 [trainer.py] => memory_per_class: 0
2025-11-27 14:21:19,972 [trainer.py] => fixed_memory: True
2025-11-27 14:21:19,972 [trainer.py] => shuffle: False
2025-11-27 14:21:19,972 [trainer.py] => init_cls: 10
2025-11-27 14:21:19,972 [trainer.py] => increment: 10
2025-11-27 14:21:19,972 [trainer.py] => model_name: inflora
2025-11-27 14:21:19,972 [trainer.py] => net_type: sip
2025-11-27 14:21:19,972 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 14:21:19,972 [trainer.py] => pretrained: True
2025-11-27 14:21:19,972 [trainer.py] => embd_dim: 768
2025-11-27 14:21:19,972 [trainer.py] => num_heads: 12
2025-11-27 14:21:19,972 [trainer.py] => total_sessions: 10
2025-11-27 14:21:19,972 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 14:21:19,972 [trainer.py] => seed: 0
2025-11-27 14:21:19,972 [trainer.py] => EPSILON: 1e-08
2025-11-27 14:21:19,972 [trainer.py] => optim: adam
2025-11-27 14:21:19,972 [trainer.py] => init_epoch: 20
2025-11-27 14:21:19,972 [trainer.py] => init_lr: 0.0005
2025-11-27 14:21:19,972 [trainer.py] => init_lr_decay: 0.1
2025-11-27 14:21:19,972 [trainer.py] => init_weight_decay: 0.0
2025-11-27 14:21:19,972 [trainer.py] => epochs: 20
2025-11-27 14:21:19,972 [trainer.py] => lrate: 0.0005
2025-11-27 14:21:19,972 [trainer.py] => lrate_decay: 0.1
2025-11-27 14:21:19,972 [trainer.py] => batch_size: 128
2025-11-27 14:21:19,973 [trainer.py] => weight_decay: 0.0
2025-11-27 14:21:19,973 [trainer.py] => rank: 10
2025-11-27 14:21:19,973 [trainer.py] => lamb: 0.95
2025-11-27 14:21:19,973 [trainer.py] => lame: 1.0
2025-11-27 14:21:19,973 [trainer.py] => num_workers: 8
2025-11-27 14:21:26,735 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2025-11-27 14:21:29,549 [sinet_inflora.py] => Using vit_base_patch16_224_in21k instead of vit_base_patch16_224 for better pretrained weights
2025-11-27 14:21:29,550 [sinet_inflora.py] => Creating SiNet with variant=vit_base_patch16_224_in21k, pretrained=True
2025-11-27 14:21:31,073 [sinet_inflora.py] => Loading pretrained weights for vit_base_patch16_224_in21k using timm...
2025-11-27 14:21:32,295 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-11-27 14:21:32,708 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 14:21:34,989 [sinet_inflora.py] => Successfully loaded using direct import from timm.models.vision_transformer
2025-11-27 14:21:35,017 [sinet_inflora.py] => Missing keys (non-LoRA): ['cls_token_grow', 'pos_embed_grow', 'head.weight', 'head.bias']...
2025-11-27 14:21:35,017 [sinet_inflora.py] => Successfully loaded 150/150 pretrained weights for vit_base_patch16_224_in21k
2025-11-27 14:21:35,043 [trainer.py] => All params: 111194651
2025-11-27 14:21:35,045 [trainer.py] => Trainable params: 111194651
2025-11-27 14:21:35,045 [inflora.py] => Learning on 0-10
2025-11-27 14:21:56,528 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight'}
2025-11-27 14:23:38,748 [trainer.py] => config: exps/inflora_c100.json
2025-11-27 14:23:38,749 [trainer.py] => prefix: reproduce
2025-11-27 14:23:38,749 [trainer.py] => dataset: cifar224
2025-11-27 14:23:38,749 [trainer.py] => memory_size: 0
2025-11-27 14:23:38,749 [trainer.py] => memory_per_class: 0
2025-11-27 14:23:38,749 [trainer.py] => fixed_memory: True
2025-11-27 14:23:38,749 [trainer.py] => shuffle: False
2025-11-27 14:23:38,749 [trainer.py] => init_cls: 10
2025-11-27 14:23:38,750 [trainer.py] => increment: 10
2025-11-27 14:23:38,750 [trainer.py] => model_name: inflora
2025-11-27 14:23:38,750 [trainer.py] => net_type: sip
2025-11-27 14:23:38,750 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 14:23:38,750 [trainer.py] => pretrained: True
2025-11-27 14:23:38,750 [trainer.py] => embd_dim: 768
2025-11-27 14:23:38,750 [trainer.py] => num_heads: 12
2025-11-27 14:23:38,750 [trainer.py] => total_sessions: 10
2025-11-27 14:23:38,750 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 14:23:38,750 [trainer.py] => seed: 0
2025-11-27 14:23:38,750 [trainer.py] => EPSILON: 1e-08
2025-11-27 14:23:38,750 [trainer.py] => optim: adam
2025-11-27 14:23:38,750 [trainer.py] => init_epoch: 1
2025-11-27 14:23:38,751 [trainer.py] => init_lr: 0.0005
2025-11-27 14:23:38,751 [trainer.py] => init_lr_decay: 0.1
2025-11-27 14:23:38,751 [trainer.py] => init_weight_decay: 0.0
2025-11-27 14:23:38,751 [trainer.py] => epochs: 20
2025-11-27 14:23:38,751 [trainer.py] => lrate: 0.0005
2025-11-27 14:23:38,751 [trainer.py] => lrate_decay: 0.1
2025-11-27 14:23:38,751 [trainer.py] => batch_size: 128
2025-11-27 14:23:38,751 [trainer.py] => weight_decay: 0.0
2025-11-27 14:23:38,751 [trainer.py] => rank: 10
2025-11-27 14:23:38,751 [trainer.py] => lamb: 0.95
2025-11-27 14:23:38,751 [trainer.py] => lame: 1.0
2025-11-27 14:23:38,751 [trainer.py] => num_workers: 8
2025-11-27 14:23:44,021 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2025-11-27 14:23:45,597 [sinet_inflora.py] => Using vit_base_patch16_224_in21k instead of vit_base_patch16_224 for better pretrained weights
2025-11-27 14:23:45,597 [sinet_inflora.py] => Creating SiNet with variant=vit_base_patch16_224_in21k, pretrained=True
2025-11-27 14:23:47,087 [sinet_inflora.py] => Loading pretrained weights for vit_base_patch16_224_in21k using timm...
2025-11-27 14:23:48,171 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-11-27 14:23:48,510 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 14:23:48,575 [sinet_inflora.py] => Successfully loaded using direct import from timm.models.vision_transformer
2025-11-27 14:23:48,601 [sinet_inflora.py] => Missing keys (non-LoRA): ['cls_token_grow', 'pos_embed_grow', 'head.weight', 'head.bias']...
2025-11-27 14:23:48,601 [sinet_inflora.py] => Successfully loaded 150/150 pretrained weights for vit_base_patch16_224_in21k
2025-11-27 14:23:48,623 [trainer.py] => All params: 111194651
2025-11-27 14:23:48,625 [trainer.py] => Trainable params: 111194651
2025-11-27 14:23:48,625 [inflora.py] => Learning on 0-10
2025-11-27 14:24:12,188 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight'}
2025-11-27 14:27:13,317 [trainer.py] => config: exps/inflora_c100.json
2025-11-27 14:27:13,319 [trainer.py] => prefix: reproduce
2025-11-27 14:27:13,319 [trainer.py] => dataset: cifar224
2025-11-27 14:27:13,319 [trainer.py] => memory_size: 0
2025-11-27 14:27:13,319 [trainer.py] => memory_per_class: 0
2025-11-27 14:27:13,319 [trainer.py] => fixed_memory: True
2025-11-27 14:27:13,319 [trainer.py] => shuffle: False
2025-11-27 14:27:13,319 [trainer.py] => init_cls: 10
2025-11-27 14:27:13,319 [trainer.py] => increment: 10
2025-11-27 14:27:13,319 [trainer.py] => model_name: inflora
2025-11-27 14:27:13,319 [trainer.py] => net_type: sip
2025-11-27 14:27:13,319 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 14:27:13,319 [trainer.py] => pretrained: True
2025-11-27 14:27:13,319 [trainer.py] => embd_dim: 768
2025-11-27 14:27:13,319 [trainer.py] => num_heads: 12
2025-11-27 14:27:13,319 [trainer.py] => total_sessions: 10
2025-11-27 14:27:13,319 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 14:27:13,319 [trainer.py] => seed: 0
2025-11-27 14:27:13,320 [trainer.py] => EPSILON: 1e-08
2025-11-27 14:27:13,320 [trainer.py] => optim: adam
2025-11-27 14:27:13,320 [trainer.py] => init_epoch: 2
2025-11-27 14:27:13,320 [trainer.py] => init_lr: 0.0005
2025-11-27 14:27:13,320 [trainer.py] => init_lr_decay: 0.1
2025-11-27 14:27:13,320 [trainer.py] => init_weight_decay: 0.0
2025-11-27 14:27:13,320 [trainer.py] => epochs: 20
2025-11-27 14:27:13,320 [trainer.py] => lrate: 0.0005
2025-11-27 14:27:13,320 [trainer.py] => lrate_decay: 0.1
2025-11-27 14:27:13,320 [trainer.py] => batch_size: 128
2025-11-27 14:27:13,320 [trainer.py] => weight_decay: 0.0
2025-11-27 14:27:13,320 [trainer.py] => rank: 10
2025-11-27 14:27:13,320 [trainer.py] => lamb: 0.95
2025-11-27 14:27:13,320 [trainer.py] => lame: 1.0
2025-11-27 14:27:13,320 [trainer.py] => num_workers: 8
2025-11-27 14:27:18,165 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2025-11-27 14:27:19,840 [sinet_inflora.py] => Using vit_base_patch16_224_in21k instead of vit_base_patch16_224 for better pretrained weights
2025-11-27 14:27:19,840 [sinet_inflora.py] => Creating SiNet with variant=vit_base_patch16_224_in21k, pretrained=True
2025-11-27 14:27:21,358 [sinet_inflora.py] => Loading pretrained weights for vit_base_patch16_224_in21k using timm...
2025-11-27 14:27:22,487 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-11-27 14:27:22,847 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 14:27:23,144 [sinet_inflora.py] => Successfully loaded using direct import from timm.models.vision_transformer
2025-11-27 14:27:23,171 [sinet_inflora.py] => Missing keys (non-LoRA): ['cls_token_grow', 'pos_embed_grow', 'head.weight', 'head.bias']...
2025-11-27 14:27:23,172 [sinet_inflora.py] => Successfully loaded 150/150 pretrained weights for vit_base_patch16_224_in21k
2025-11-27 14:27:23,195 [trainer.py] => All params: 111194651
2025-11-27 14:27:23,197 [trainer.py] => Trainable params: 111194651
2025-11-27 14:27:23,197 [inflora.py] => Learning on 0-10
2025-11-27 14:27:45,763 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight'}
2025-11-27 14:28:52,084 [inflora.py] => Task 0, Epoch 2/2 => Loss 0.259, Train_accy 91.82
2025-11-27 14:29:08,983 [inflora.py] => Threshold: 0.95
2025-11-27 14:29:11,718 [inflora.py] => ----------------------------------------
2025-11-27 14:29:11,718 [inflora.py] => Gradient Constraints Summary
2025-11-27 14:29:11,718 [inflora.py] => ----------------------------------------
2025-11-27 14:29:11,719 [inflora.py] => 1 layer constraint size: 6
2025-11-27 14:29:11,719 [inflora.py] => 2 layer constraint size: 9
2025-11-27 14:29:11,719 [inflora.py] => 3 layer constraint size: 10
2025-11-27 14:29:11,719 [inflora.py] => 4 layer constraint size: 10
2025-11-27 14:29:11,719 [inflora.py] => 5 layer constraint size: 13
2025-11-27 14:29:11,719 [inflora.py] => 6 layer constraint size: 14
2025-11-27 14:29:11,719 [inflora.py] => 7 layer constraint size: 11
2025-11-27 14:29:11,719 [inflora.py] => 8 layer constraint size: 13
2025-11-27 14:29:11,719 [inflora.py] => 9 layer constraint size: 11
2025-11-27 14:29:11,719 [inflora.py] => 10 layer constraint size: 9
2025-11-27 14:29:11,719 [inflora.py] => 11 layer constraint size: 3
2025-11-27 14:29:11,719 [inflora.py] => 12 layer constraint size: 9
2025-11-27 14:29:11,720 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:11,721 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:11,723 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:11,725 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:11,727 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:11,728 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:11,729 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:11,731 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:11,732 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:11,733 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:11,734 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:11,735 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:29:31,769 [inflora.py] => Exemplar size: 0
2025-11-27 14:29:31,769 [trainer.py] => No NME accuracy.
2025-11-27 14:29:31,770 [trainer.py] => CNN: {'total': np.float64(99.1), '00-09': np.float64(99.1), 'old': 0, 'new': np.float64(99.1)}
2025-11-27 14:29:31,770 [trainer.py] => CNN top1 curve: [np.float64(99.1)]
2025-11-27 14:29:31,770 [trainer.py] => CNN top5 curve: [np.float64(100.0)]

2025-11-27 14:29:31,770 [trainer.py] => Average Accuracy (CNN): 99.1 

2025-11-27 14:29:31,772 [trainer.py] => All params: 111194651
2025-11-27 14:29:31,774 [trainer.py] => Trainable params: 192010
2025-11-27 14:29:31,774 [inflora.py] => Learning on 10-20
2025-11-27 14:29:50,419 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_v.1.weight', 'image_encoder.blocks.7.attn.lora_B_k.1.weight', 'classifier_pool.1.bias', 'image_encoder.blocks.10.attn.lora_B_k.1.weight', 'image_encoder.blocks.6.attn.lora_B_v.1.weight', 'image_encoder.blocks.9.attn.lora_B_k.1.weight', 'image_encoder.blocks.3.attn.lora_B_v.1.weight', 'image_encoder.blocks.6.attn.lora_B_k.1.weight', 'classifier_pool.1.weight', 'image_encoder.blocks.3.attn.lora_B_k.1.weight', 'image_encoder.blocks.5.attn.lora_B_v.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.1.weight', 'image_encoder.blocks.8.attn.lora_B_k.1.weight', 'image_encoder.blocks.0.attn.lora_B_k.1.weight', 'image_encoder.blocks.8.attn.lora_B_v.1.weight', 'image_encoder.blocks.1.attn.lora_B_k.1.weight', 'image_encoder.blocks.2.attn.lora_B_k.1.weight', 'image_encoder.blocks.4.attn.lora_B_k.1.weight', 'image_encoder.blocks.7.attn.lora_B_v.1.weight', 'image_encoder.blocks.11.attn.lora_B_k.1.weight', 'image_encoder.blocks.9.attn.lora_B_v.1.weight', 'image_encoder.blocks.5.attn.lora_B_k.1.weight', 'image_encoder.blocks.0.attn.lora_B_v.1.weight', 'image_encoder.blocks.11.attn.lora_B_v.1.weight', 'image_encoder.blocks.2.attn.lora_B_v.1.weight', 'image_encoder.blocks.4.attn.lora_B_v.1.weight'}
2025-11-27 14:30:44,591 [trainer.py] => config: exps/inflora_c100.json
2025-11-27 14:30:44,591 [trainer.py] => prefix: reproduce
2025-11-27 14:30:44,592 [trainer.py] => dataset: cifar224
2025-11-27 14:30:44,592 [trainer.py] => memory_size: 0
2025-11-27 14:30:44,592 [trainer.py] => memory_per_class: 0
2025-11-27 14:30:44,592 [trainer.py] => fixed_memory: True
2025-11-27 14:30:44,592 [trainer.py] => shuffle: False
2025-11-27 14:30:44,592 [trainer.py] => init_cls: 10
2025-11-27 14:30:44,592 [trainer.py] => increment: 10
2025-11-27 14:30:44,592 [trainer.py] => model_name: inflora
2025-11-27 14:30:44,592 [trainer.py] => net_type: sip
2025-11-27 14:30:44,592 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 14:30:44,592 [trainer.py] => pretrained: True
2025-11-27 14:30:44,592 [trainer.py] => embd_dim: 768
2025-11-27 14:30:44,592 [trainer.py] => num_heads: 12
2025-11-27 14:30:44,592 [trainer.py] => total_sessions: 10
2025-11-27 14:30:44,592 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 14:30:44,592 [trainer.py] => seed: 0
2025-11-27 14:30:44,592 [trainer.py] => EPSILON: 1e-08
2025-11-27 14:30:44,592 [trainer.py] => optim: adam
2025-11-27 14:30:44,592 [trainer.py] => init_epoch: 10
2025-11-27 14:30:44,592 [trainer.py] => init_lr: 0.0005
2025-11-27 14:30:44,592 [trainer.py] => init_lr_decay: 0.1
2025-11-27 14:30:44,592 [trainer.py] => init_weight_decay: 0.0
2025-11-27 14:30:44,593 [trainer.py] => epochs: 10
2025-11-27 14:30:44,593 [trainer.py] => lrate: 0.0005
2025-11-27 14:30:44,593 [trainer.py] => lrate_decay: 0.1
2025-11-27 14:30:44,593 [trainer.py] => batch_size: 128
2025-11-27 14:30:44,593 [trainer.py] => weight_decay: 0.0
2025-11-27 14:30:44,593 [trainer.py] => rank: 10
2025-11-27 14:30:44,593 [trainer.py] => lamb: 0.95
2025-11-27 14:30:44,593 [trainer.py] => lame: 1.0
2025-11-27 14:30:44,593 [trainer.py] => num_workers: 8
2025-11-27 14:30:49,281 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2025-11-27 14:30:51,160 [sinet_inflora.py] => Using vit_base_patch16_224_in21k instead of vit_base_patch16_224 for better pretrained weights
2025-11-27 14:30:51,160 [sinet_inflora.py] => Creating SiNet with variant=vit_base_patch16_224_in21k, pretrained=True
2025-11-27 14:30:52,807 [sinet_inflora.py] => Loading pretrained weights for vit_base_patch16_224_in21k using timm...
2025-11-27 14:30:53,915 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-11-27 14:30:54,516 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 14:30:54,580 [sinet_inflora.py] => Successfully loaded using direct import from timm.models.vision_transformer
2025-11-27 14:30:54,617 [sinet_inflora.py] => Missing keys (non-LoRA): ['cls_token_grow', 'pos_embed_grow', 'head.weight', 'head.bias']...
2025-11-27 14:30:54,617 [sinet_inflora.py] => Successfully loaded 150/150 pretrained weights for vit_base_patch16_224_in21k
2025-11-27 14:30:54,642 [trainer.py] => All params: 111194651
2025-11-27 14:30:54,644 [trainer.py] => Trainable params: 111194651
2025-11-27 14:30:54,644 [inflora.py] => Learning on 0-10
2025-11-27 14:31:15,587 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'classifier_pool.0.bias', 'classifier_pool.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight'}
2025-11-27 14:36:53,521 [inflora.py] => Task 0, Epoch 10/10 => Loss 0.169, Train_accy 94.58
2025-11-27 14:37:10,636 [inflora.py] => Threshold: 0.95
2025-11-27 14:37:13,841 [inflora.py] => ----------------------------------------
2025-11-27 14:37:13,841 [inflora.py] => Gradient Constraints Summary
2025-11-27 14:37:13,842 [inflora.py] => ----------------------------------------
2025-11-27 14:37:13,842 [inflora.py] => 1 layer constraint size: 6
2025-11-27 14:37:13,842 [inflora.py] => 2 layer constraint size: 9
2025-11-27 14:37:13,842 [inflora.py] => 3 layer constraint size: 11
2025-11-27 14:37:13,842 [inflora.py] => 4 layer constraint size: 10
2025-11-27 14:37:13,842 [inflora.py] => 5 layer constraint size: 12
2025-11-27 14:37:13,842 [inflora.py] => 6 layer constraint size: 13
2025-11-27 14:37:13,842 [inflora.py] => 7 layer constraint size: 12
2025-11-27 14:37:13,842 [inflora.py] => 8 layer constraint size: 17
2025-11-27 14:37:13,843 [inflora.py] => 9 layer constraint size: 17
2025-11-27 14:37:13,843 [inflora.py] => 10 layer constraint size: 14
2025-11-27 14:37:13,843 [inflora.py] => 11 layer constraint size: 5
2025-11-27 14:37:13,843 [inflora.py] => 12 layer constraint size: 9
2025-11-27 14:37:13,849 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:13,852 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:13,853 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:13,856 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:13,858 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:13,861 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:13,864 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:13,867 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:13,869 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:13,871 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:13,877 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:13,879 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:37:34,684 [inflora.py] => Exemplar size: 0
2025-11-27 14:37:34,684 [trainer.py] => No NME accuracy.
2025-11-27 14:37:34,684 [trainer.py] => CNN: {'total': np.float64(99.3), '00-09': np.float64(99.3), 'old': 0, 'new': np.float64(99.3)}
2025-11-27 14:37:34,685 [trainer.py] => CNN top1 curve: [np.float64(99.3)]
2025-11-27 14:37:34,685 [trainer.py] => CNN top5 curve: [np.float64(100.0)]

2025-11-27 14:37:34,685 [trainer.py] => Average Accuracy (CNN): 99.3 

2025-11-27 14:37:34,687 [trainer.py] => All params: 111194651
2025-11-27 14:37:34,689 [trainer.py] => Trainable params: 192010
2025-11-27 14:37:34,689 [inflora.py] => Learning on 10-20
2025-11-27 14:37:53,416 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.5.attn.lora_B_k.1.weight', 'image_encoder.blocks.6.attn.lora_B_v.1.weight', 'image_encoder.blocks.1.attn.lora_B_v.1.weight', 'image_encoder.blocks.2.attn.lora_B_k.1.weight', 'image_encoder.blocks.6.attn.lora_B_k.1.weight', 'image_encoder.blocks.4.attn.lora_B_k.1.weight', 'image_encoder.blocks.9.attn.lora_B_k.1.weight', 'image_encoder.blocks.0.attn.lora_B_k.1.weight', 'image_encoder.blocks.7.attn.lora_B_v.1.weight', 'image_encoder.blocks.9.attn.lora_B_v.1.weight', 'image_encoder.blocks.11.attn.lora_B_k.1.weight', 'classifier_pool.1.bias', 'image_encoder.blocks.11.attn.lora_B_v.1.weight', 'classifier_pool.1.weight', 'image_encoder.blocks.7.attn.lora_B_k.1.weight', 'image_encoder.blocks.3.attn.lora_B_v.1.weight', 'image_encoder.blocks.8.attn.lora_B_v.1.weight', 'image_encoder.blocks.4.attn.lora_B_v.1.weight', 'image_encoder.blocks.5.attn.lora_B_v.1.weight', 'image_encoder.blocks.2.attn.lora_B_v.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.1.weight', 'image_encoder.blocks.1.attn.lora_B_k.1.weight', 'image_encoder.blocks.8.attn.lora_B_k.1.weight', 'image_encoder.blocks.0.attn.lora_B_v.1.weight', 'image_encoder.blocks.3.attn.lora_B_k.1.weight', 'image_encoder.blocks.10.attn.lora_B_k.1.weight'}
2025-11-27 14:43:31,004 [inflora.py] => Task 1, Epoch 10/10 => Loss 0.228, Train_accy 93.28
2025-11-27 14:43:48,703 [inflora.py] => Threshold: 0.955
2025-11-27 14:48:24,446 [trainer.py] => config: exps/inflora_c100.json
2025-11-27 14:48:24,447 [trainer.py] => prefix: reproduce
2025-11-27 14:48:24,447 [trainer.py] => dataset: cifar224
2025-11-27 14:48:24,447 [trainer.py] => memory_size: 0
2025-11-27 14:48:24,447 [trainer.py] => memory_per_class: 0
2025-11-27 14:48:24,447 [trainer.py] => fixed_memory: True
2025-11-27 14:48:24,447 [trainer.py] => shuffle: False
2025-11-27 14:48:24,447 [trainer.py] => init_cls: 10
2025-11-27 14:48:24,448 [trainer.py] => increment: 10
2025-11-27 14:48:24,448 [trainer.py] => model_name: inflora
2025-11-27 14:48:24,448 [trainer.py] => net_type: sip
2025-11-27 14:48:24,448 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 14:48:24,448 [trainer.py] => pretrained: True
2025-11-27 14:48:24,448 [trainer.py] => embd_dim: 768
2025-11-27 14:48:24,448 [trainer.py] => num_heads: 12
2025-11-27 14:48:24,448 [trainer.py] => total_sessions: 10
2025-11-27 14:48:24,448 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 14:48:24,448 [trainer.py] => seed: 0
2025-11-27 14:48:24,448 [trainer.py] => EPSILON: 1e-08
2025-11-27 14:48:24,448 [trainer.py] => optim: adam
2025-11-27 14:48:24,448 [trainer.py] => init_epoch: 10
2025-11-27 14:48:24,448 [trainer.py] => init_lr: 0.0005
2025-11-27 14:48:24,448 [trainer.py] => init_lr_decay: 0.1
2025-11-27 14:48:24,448 [trainer.py] => init_weight_decay: 0.0
2025-11-27 14:48:24,448 [trainer.py] => epochs: 10
2025-11-27 14:48:24,448 [trainer.py] => lrate: 0.0005
2025-11-27 14:48:24,448 [trainer.py] => lrate_decay: 0.1
2025-11-27 14:48:24,448 [trainer.py] => batch_size: 128
2025-11-27 14:48:24,448 [trainer.py] => weight_decay: 0.0
2025-11-27 14:48:24,448 [trainer.py] => rank: 10
2025-11-27 14:48:24,448 [trainer.py] => lamb: 0.95
2025-11-27 14:48:24,448 [trainer.py] => lame: 1.0
2025-11-27 14:48:24,449 [trainer.py] => num_workers: 8
2025-11-27 14:48:28,933 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2025-11-27 14:48:30,844 [sinet_inflora.py] => Using vit_base_patch16_224_in21k instead of vit_base_patch16_224 for better pretrained weights
2025-11-27 14:48:30,844 [sinet_inflora.py] => Creating SiNet with variant=vit_base_patch16_224_in21k, pretrained=True
2025-11-27 14:48:32,441 [sinet_inflora.py] => Loading pretrained weights for vit_base_patch16_224_in21k using timm...
2025-11-27 14:48:33,587 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-11-27 14:48:33,991 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 14:48:34,377 [sinet_inflora.py] => Successfully loaded using direct import from timm.models.vision_transformer
2025-11-27 14:48:34,404 [sinet_inflora.py] => Missing keys (non-LoRA): ['cls_token_grow', 'pos_embed_grow', 'head.weight', 'head.bias']...
2025-11-27 14:48:34,405 [sinet_inflora.py] => Successfully loaded 150/150 pretrained weights for vit_base_patch16_224_in21k
2025-11-27 14:48:34,427 [trainer.py] => All params: 111194651
2025-11-27 14:48:34,429 [trainer.py] => Trainable params: 111194651
2025-11-27 14:48:34,429 [inflora.py] => Learning on 0-10
2025-11-27 14:49:12,385 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight'}
2025-11-27 14:53:14,292 [trainer.py] => config: exps/inflora_c100.json
2025-11-27 14:53:14,293 [trainer.py] => prefix: reproduce
2025-11-27 14:53:14,293 [trainer.py] => dataset: cifar224
2025-11-27 14:53:14,293 [trainer.py] => memory_size: 0
2025-11-27 14:53:14,294 [trainer.py] => memory_per_class: 0
2025-11-27 14:53:14,294 [trainer.py] => fixed_memory: True
2025-11-27 14:53:14,294 [trainer.py] => shuffle: False
2025-11-27 14:53:14,294 [trainer.py] => init_cls: 10
2025-11-27 14:53:14,294 [trainer.py] => increment: 10
2025-11-27 14:53:14,294 [trainer.py] => model_name: inflora
2025-11-27 14:53:14,294 [trainer.py] => net_type: sip
2025-11-27 14:53:14,294 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 14:53:14,294 [trainer.py] => pretrained: True
2025-11-27 14:53:14,294 [trainer.py] => embd_dim: 768
2025-11-27 14:53:14,294 [trainer.py] => num_heads: 12
2025-11-27 14:53:14,294 [trainer.py] => total_sessions: 10
2025-11-27 14:53:14,294 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 14:53:14,294 [trainer.py] => seed: 0
2025-11-27 14:53:14,294 [trainer.py] => EPSILON: 1e-08
2025-11-27 14:53:14,294 [trainer.py] => optim: adam
2025-11-27 14:53:14,295 [trainer.py] => init_epoch: 2
2025-11-27 14:53:14,295 [trainer.py] => init_lr: 0.0005
2025-11-27 14:53:14,295 [trainer.py] => init_lr_decay: 0.1
2025-11-27 14:53:14,295 [trainer.py] => init_weight_decay: 0.0
2025-11-27 14:53:14,295 [trainer.py] => epochs: 2
2025-11-27 14:53:14,295 [trainer.py] => lrate: 0.0005
2025-11-27 14:53:14,295 [trainer.py] => lrate_decay: 0.1
2025-11-27 14:53:14,295 [trainer.py] => batch_size: 128
2025-11-27 14:53:14,295 [trainer.py] => weight_decay: 0.0
2025-11-27 14:53:14,295 [trainer.py] => rank: 10
2025-11-27 14:53:14,295 [trainer.py] => lamb: 0.95
2025-11-27 14:53:14,295 [trainer.py] => lame: 1.0
2025-11-27 14:53:14,295 [trainer.py] => num_workers: 8
2025-11-27 14:53:18,706 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2025-11-27 14:53:20,432 [sinet_inflora.py] => Using vit_base_patch16_224_in21k instead of vit_base_patch16_224 for better pretrained weights
2025-11-27 14:53:20,433 [sinet_inflora.py] => Creating SiNet with variant=vit_base_patch16_224_in21k, pretrained=True
2025-11-27 14:53:22,011 [sinet_inflora.py] => Loading pretrained weights for vit_base_patch16_224_in21k using timm...
2025-11-27 14:53:23,123 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-11-27 14:53:23,674 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 14:53:23,772 [sinet_inflora.py] => Successfully loaded using direct import from timm.models.vision_transformer
2025-11-27 14:53:23,800 [sinet_inflora.py] => Missing keys (non-LoRA): ['cls_token_grow', 'pos_embed_grow', 'head.weight', 'head.bias']...
2025-11-27 14:53:23,800 [sinet_inflora.py] => Successfully loaded 150/150 pretrained weights for vit_base_patch16_224_in21k
2025-11-27 14:53:23,821 [trainer.py] => All params: 111194651
2025-11-27 14:53:23,823 [trainer.py] => Trainable params: 111194651
2025-11-27 14:53:23,824 [inflora.py] => Learning on 0-10
2025-11-27 14:53:44,396 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight'}
2025-11-27 14:54:51,050 [inflora.py] => Task 0, Epoch 2/2 => Loss 0.259, Train_accy 91.82
2025-11-27 14:55:08,180 [inflora.py] => Threshold: 0.95
2025-11-27 14:55:10,999 [inflora.py] => ----------------------------------------
2025-11-27 14:55:11,000 [inflora.py] => Gradient Constraints Summary
2025-11-27 14:55:11,000 [inflora.py] => ----------------------------------------
2025-11-27 14:55:11,000 [inflora.py] => 1 layer constraint size: 6
2025-11-27 14:55:11,000 [inflora.py] => 2 layer constraint size: 9
2025-11-27 14:55:11,000 [inflora.py] => 3 layer constraint size: 10
2025-11-27 14:55:11,000 [inflora.py] => 4 layer constraint size: 10
2025-11-27 14:55:11,000 [inflora.py] => 5 layer constraint size: 13
2025-11-27 14:55:11,000 [inflora.py] => 6 layer constraint size: 14
2025-11-27 14:55:11,000 [inflora.py] => 7 layer constraint size: 11
2025-11-27 14:55:11,000 [inflora.py] => 8 layer constraint size: 13
2025-11-27 14:55:11,000 [inflora.py] => 9 layer constraint size: 11
2025-11-27 14:55:11,000 [inflora.py] => 10 layer constraint size: 9
2025-11-27 14:55:11,000 [inflora.py] => 11 layer constraint size: 3
2025-11-27 14:55:11,000 [inflora.py] => 12 layer constraint size: 9
2025-11-27 14:55:11,003 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:11,004 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:11,005 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:11,007 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:11,012 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:11,014 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:11,018 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:11,020 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:11,024 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:11,027 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:11,028 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:11,029 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:55:31,725 [inflora.py] => Exemplar size: 0
2025-11-27 14:55:31,725 [trainer.py] => No NME accuracy.
2025-11-27 14:55:31,726 [trainer.py] => CNN: {'total': np.float64(99.1), '00-09': np.float64(99.1), 'old': 0, 'new': np.float64(99.1)}
2025-11-27 14:55:31,726 [trainer.py] => CNN top1 curve: [np.float64(99.1)]
2025-11-27 14:55:31,726 [trainer.py] => CNN top5 curve: [np.float64(100.0)]

2025-11-27 14:55:31,726 [trainer.py] => Average Accuracy (CNN): 99.1 

2025-11-27 14:55:31,731 [trainer.py] => All params: 111194651
2025-11-27 14:55:31,733 [trainer.py] => Trainable params: 192010
2025-11-27 14:55:31,734 [inflora.py] => Learning on 10-20
2025-11-27 14:55:50,417 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.6.attn.lora_B_v.1.weight', 'image_encoder.blocks.6.attn.lora_B_k.1.weight', 'classifier_pool.1.weight', 'image_encoder.blocks.7.attn.lora_B_v.1.weight', 'image_encoder.blocks.11.attn.lora_B_v.1.weight', 'image_encoder.blocks.9.attn.lora_B_v.1.weight', 'image_encoder.blocks.0.attn.lora_B_k.1.weight', 'image_encoder.blocks.10.attn.lora_B_k.1.weight', 'classifier_pool.1.bias', 'image_encoder.blocks.8.attn.lora_B_v.1.weight', 'image_encoder.blocks.11.attn.lora_B_k.1.weight', 'image_encoder.blocks.4.attn.lora_B_v.1.weight', 'image_encoder.blocks.4.attn.lora_B_k.1.weight', 'image_encoder.blocks.2.attn.lora_B_v.1.weight', 'image_encoder.blocks.9.attn.lora_B_k.1.weight', 'image_encoder.blocks.1.attn.lora_B_k.1.weight', 'image_encoder.blocks.5.attn.lora_B_k.1.weight', 'image_encoder.blocks.3.attn.lora_B_v.1.weight', 'image_encoder.blocks.3.attn.lora_B_k.1.weight', 'image_encoder.blocks.8.attn.lora_B_k.1.weight', 'image_encoder.blocks.5.attn.lora_B_v.1.weight', 'image_encoder.blocks.1.attn.lora_B_v.1.weight', 'image_encoder.blocks.0.attn.lora_B_v.1.weight', 'image_encoder.blocks.7.attn.lora_B_k.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.1.weight', 'image_encoder.blocks.2.attn.lora_B_k.1.weight'}
2025-11-27 14:57:01,111 [inflora.py] => Task 1, Epoch 2/2 => Loss 0.326, Train_accy 89.82
2025-11-27 14:57:18,519 [inflora.py] => Threshold: 0.955
2025-11-27 14:57:24,686 [inflora.py] => ----------------------------------------
2025-11-27 14:57:24,687 [inflora.py] => Gradient Constraints Summary
2025-11-27 14:57:24,687 [inflora.py] => ----------------------------------------
2025-11-27 14:57:24,687 [inflora.py] => 1 layer constraint size: 7
2025-11-27 14:57:24,687 [inflora.py] => 2 layer constraint size: 10
2025-11-27 14:57:24,687 [inflora.py] => 3 layer constraint size: 12
2025-11-27 14:57:24,687 [inflora.py] => 4 layer constraint size: 12
2025-11-27 14:57:24,687 [inflora.py] => 5 layer constraint size: 16
2025-11-27 14:57:24,687 [inflora.py] => 6 layer constraint size: 18
2025-11-27 14:57:24,687 [inflora.py] => 7 layer constraint size: 16
2025-11-27 14:57:24,687 [inflora.py] => 8 layer constraint size: 19
2025-11-27 14:57:24,687 [inflora.py] => 9 layer constraint size: 19
2025-11-27 14:57:24,687 [inflora.py] => 10 layer constraint size: 18
2025-11-27 14:57:24,688 [inflora.py] => 11 layer constraint size: 5
2025-11-27 14:57:24,688 [inflora.py] => 12 layer constraint size: 19
2025-11-27 14:57:24,696 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:24,715 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:24,719 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:24,740 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:24,759 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:24,764 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:24,771 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:24,775 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:24,780 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:24,784 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:24,788 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:24,790 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:57:47,747 [inflora.py] => Exemplar size: 0
2025-11-27 14:57:47,748 [trainer.py] => No NME accuracy.
2025-11-27 14:57:47,749 [trainer.py] => CNN: {'total': np.float64(6.5), '00-09': np.float64(13.0), '10-19': np.float64(0.0), 'old': np.float64(13.0), 'new': np.float64(0.0)}
2025-11-27 14:57:47,749 [trainer.py] => CNN top1 curve: [np.float64(99.1), np.float64(6.5)]
2025-11-27 14:57:47,749 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(17.1)]

2025-11-27 14:57:47,749 [trainer.py] => Average Accuracy (CNN): 52.8 

2025-11-27 14:57:47,752 [trainer.py] => All params: 111194651
2025-11-27 14:57:47,756 [trainer.py] => Trainable params: 192010
2025-11-27 14:57:47,756 [inflora.py] => Learning on 20-30
2025-11-27 14:58:06,832 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_k.2.weight', 'classifier_pool.2.bias', 'image_encoder.blocks.6.attn.lora_B_k.2.weight', 'image_encoder.blocks.8.attn.lora_B_k.2.weight', 'image_encoder.blocks.6.attn.lora_B_v.2.weight', 'image_encoder.blocks.10.attn.lora_B_k.2.weight', 'image_encoder.blocks.0.attn.lora_B_v.2.weight', 'image_encoder.blocks.2.attn.lora_B_v.2.weight', 'image_encoder.blocks.3.attn.lora_B_v.2.weight', 'image_encoder.blocks.7.attn.lora_B_k.2.weight', 'image_encoder.blocks.9.attn.lora_B_k.2.weight', 'image_encoder.blocks.5.attn.lora_B_k.2.weight', 'image_encoder.blocks.1.attn.lora_B_k.2.weight', 'image_encoder.blocks.9.attn.lora_B_v.2.weight', 'classifier_pool.2.weight', 'image_encoder.blocks.11.attn.lora_B_v.2.weight', 'image_encoder.blocks.11.attn.lora_B_k.2.weight', 'image_encoder.blocks.4.attn.lora_B_k.2.weight', 'image_encoder.blocks.4.attn.lora_B_v.2.weight', 'image_encoder.blocks.3.attn.lora_B_k.2.weight', 'image_encoder.blocks.2.attn.lora_B_k.2.weight', 'image_encoder.blocks.10.attn.lora_B_v.2.weight', 'image_encoder.blocks.5.attn.lora_B_v.2.weight', 'image_encoder.blocks.7.attn.lora_B_v.2.weight', 'image_encoder.blocks.8.attn.lora_B_v.2.weight', 'image_encoder.blocks.1.attn.lora_B_v.2.weight'}
2025-11-27 14:59:14,313 [inflora.py] => Task 2, Epoch 2/2 => Loss 0.307, Train_accy 90.58
2025-11-27 14:59:31,772 [inflora.py] => Threshold: 0.96
2025-11-27 14:59:32,248 [inflora.py] => Skip Updating DualGPM for layer: 1
2025-11-27 14:59:37,568 [inflora.py] => ----------------------------------------
2025-11-27 14:59:37,568 [inflora.py] => Gradient Constraints Summary
2025-11-27 14:59:37,568 [inflora.py] => ----------------------------------------
2025-11-27 14:59:37,568 [inflora.py] => 1 layer constraint size: 7
2025-11-27 14:59:37,568 [inflora.py] => 2 layer constraint size: 11
2025-11-27 14:59:37,568 [inflora.py] => 3 layer constraint size: 14
2025-11-27 14:59:37,568 [inflora.py] => 4 layer constraint size: 15
2025-11-27 14:59:37,569 [inflora.py] => 5 layer constraint size: 18
2025-11-27 14:59:37,569 [inflora.py] => 6 layer constraint size: 21
2025-11-27 14:59:37,569 [inflora.py] => 7 layer constraint size: 21
2025-11-27 14:59:37,569 [inflora.py] => 8 layer constraint size: 27
2025-11-27 14:59:37,569 [inflora.py] => 9 layer constraint size: 27
2025-11-27 14:59:37,569 [inflora.py] => 10 layer constraint size: 24
2025-11-27 14:59:37,569 [inflora.py] => 11 layer constraint size: 9
2025-11-27 14:59:37,569 [inflora.py] => 12 layer constraint size: 27
2025-11-27 14:59:37,572 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:59:37,576 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:59:37,579 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:59:37,583 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:59:37,586 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:59:37,590 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:59:37,593 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:59:37,597 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:59:37,600 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:59:37,604 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:59:37,607 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 14:59:37,611 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:00:05,944 [inflora.py] => Exemplar size: 0
2025-11-27 15:00:05,945 [trainer.py] => No NME accuracy.
2025-11-27 15:00:05,945 [trainer.py] => CNN: {'total': np.float64(3.8), '00-09': np.float64(11.4), '10-19': np.float64(0.0), '20-29': np.float64(0.0), 'old': np.float64(5.7), 'new': np.float64(0.0)}
2025-11-27 15:00:05,945 [trainer.py] => CNN top1 curve: [np.float64(99.1), np.float64(6.5), np.float64(3.8)]
2025-11-27 15:00:05,946 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(17.1), np.float64(18.9)]

2025-11-27 15:00:05,947 [trainer.py] => Average Accuracy (CNN): 36.46666666666666 

2025-11-27 15:00:05,949 [trainer.py] => All params: 111194651
2025-11-27 15:00:05,951 [trainer.py] => Trainable params: 192010
2025-11-27 15:00:05,952 [inflora.py] => Learning on 30-40
2025-11-27 15:00:25,589 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.4.attn.lora_B_v.3.weight', 'image_encoder.blocks.5.attn.lora_B_v.3.weight', 'image_encoder.blocks.11.attn.lora_B_k.3.weight', 'image_encoder.blocks.2.attn.lora_B_k.3.weight', 'image_encoder.blocks.9.attn.lora_B_v.3.weight', 'image_encoder.blocks.2.attn.lora_B_v.3.weight', 'image_encoder.blocks.10.attn.lora_B_v.3.weight', 'image_encoder.blocks.5.attn.lora_B_k.3.weight', 'image_encoder.blocks.6.attn.lora_B_k.3.weight', 'classifier_pool.3.bias', 'image_encoder.blocks.8.attn.lora_B_k.3.weight', 'image_encoder.blocks.0.attn.lora_B_k.3.weight', 'image_encoder.blocks.8.attn.lora_B_v.3.weight', 'image_encoder.blocks.11.attn.lora_B_v.3.weight', 'image_encoder.blocks.1.attn.lora_B_k.3.weight', 'classifier_pool.3.weight', 'image_encoder.blocks.6.attn.lora_B_v.3.weight', 'image_encoder.blocks.1.attn.lora_B_v.3.weight', 'image_encoder.blocks.9.attn.lora_B_k.3.weight', 'image_encoder.blocks.3.attn.lora_B_v.3.weight', 'image_encoder.blocks.3.attn.lora_B_k.3.weight', 'image_encoder.blocks.7.attn.lora_B_k.3.weight', 'image_encoder.blocks.10.attn.lora_B_k.3.weight', 'image_encoder.blocks.0.attn.lora_B_v.3.weight', 'image_encoder.blocks.4.attn.lora_B_k.3.weight', 'image_encoder.blocks.7.attn.lora_B_v.3.weight'}
2025-11-27 15:01:33,056 [inflora.py] => Task 3, Epoch 2/2 => Loss 0.276, Train_accy 90.88
2025-11-27 15:01:50,794 [inflora.py] => Threshold: 0.965
2025-11-27 15:01:51,425 [inflora.py] => Skip Updating DualGPM for layer: 1
2025-11-27 15:01:57,371 [inflora.py] => ----------------------------------------
2025-11-27 15:01:57,375 [inflora.py] => Gradient Constraints Summary
2025-11-27 15:01:57,375 [inflora.py] => ----------------------------------------
2025-11-27 15:01:57,375 [inflora.py] => 1 layer constraint size: 7
2025-11-27 15:01:57,375 [inflora.py] => 2 layer constraint size: 12
2025-11-27 15:01:57,375 [inflora.py] => 3 layer constraint size: 16
2025-11-27 15:01:57,375 [inflora.py] => 4 layer constraint size: 17
2025-11-27 15:01:57,375 [inflora.py] => 5 layer constraint size: 23
2025-11-27 15:01:57,375 [inflora.py] => 6 layer constraint size: 28
2025-11-27 15:01:57,375 [inflora.py] => 7 layer constraint size: 27
2025-11-27 15:01:57,375 [inflora.py] => 8 layer constraint size: 36
2025-11-27 15:01:57,376 [inflora.py] => 9 layer constraint size: 41
2025-11-27 15:01:57,376 [inflora.py] => 10 layer constraint size: 39
2025-11-27 15:01:57,376 [inflora.py] => 11 layer constraint size: 15
2025-11-27 15:01:57,376 [inflora.py] => 12 layer constraint size: 35
2025-11-27 15:01:57,381 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:01:57,385 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:01:57,449 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:01:57,454 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:01:57,458 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:01:57,462 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:01:57,466 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:01:57,471 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:01:57,476 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:01:57,480 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:01:57,488 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:01:57,493 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:02:27,101 [inflora.py] => Exemplar size: 0
2025-11-27 15:02:27,101 [trainer.py] => No NME accuracy.
2025-11-27 15:02:27,101 [trainer.py] => CNN: {'total': np.float64(1.42), '00-09': np.float64(5.7), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), 'old': np.float64(1.9), 'new': np.float64(0.0)}
2025-11-27 15:02:27,101 [trainer.py] => CNN top1 curve: [np.float64(99.1), np.float64(6.5), np.float64(3.8), np.float64(1.42)]
2025-11-27 15:02:27,101 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(17.1), np.float64(18.9), np.float64(13.55)]

2025-11-27 15:02:27,103 [trainer.py] => Average Accuracy (CNN): 27.705 

2025-11-27 15:02:27,106 [trainer.py] => All params: 111194651
2025-11-27 15:02:27,108 [trainer.py] => Trainable params: 192010
2025-11-27 15:02:27,108 [inflora.py] => Learning on 40-50
2025-11-27 15:02:46,336 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_v.4.weight', 'image_encoder.blocks.8.attn.lora_B_v.4.weight', 'image_encoder.blocks.10.attn.lora_B_v.4.weight', 'image_encoder.blocks.9.attn.lora_B_v.4.weight', 'image_encoder.blocks.0.attn.lora_B_k.4.weight', 'image_encoder.blocks.1.attn.lora_B_v.4.weight', 'image_encoder.blocks.3.attn.lora_B_v.4.weight', 'classifier_pool.4.weight', 'image_encoder.blocks.11.attn.lora_B_v.4.weight', 'image_encoder.blocks.5.attn.lora_B_k.4.weight', 'image_encoder.blocks.3.attn.lora_B_k.4.weight', 'image_encoder.blocks.2.attn.lora_B_k.4.weight', 'image_encoder.blocks.5.attn.lora_B_v.4.weight', 'classifier_pool.4.bias', 'image_encoder.blocks.1.attn.lora_B_k.4.weight', 'image_encoder.blocks.4.attn.lora_B_v.4.weight', 'image_encoder.blocks.10.attn.lora_B_k.4.weight', 'image_encoder.blocks.9.attn.lora_B_k.4.weight', 'image_encoder.blocks.7.attn.lora_B_v.4.weight', 'image_encoder.blocks.4.attn.lora_B_k.4.weight', 'image_encoder.blocks.7.attn.lora_B_k.4.weight', 'image_encoder.blocks.6.attn.lora_B_k.4.weight', 'image_encoder.blocks.2.attn.lora_B_v.4.weight', 'image_encoder.blocks.8.attn.lora_B_k.4.weight', 'image_encoder.blocks.11.attn.lora_B_k.4.weight', 'image_encoder.blocks.6.attn.lora_B_v.4.weight'}
2025-11-27 15:03:53,845 [inflora.py] => Task 4, Epoch 2/2 => Loss 0.273, Train_accy 91.06
2025-11-27 15:04:11,484 [inflora.py] => Threshold: 0.97
2025-11-27 15:04:11,957 [inflora.py] => Skip Updating DualGPM for layer: 1
2025-11-27 15:04:17,094 [inflora.py] => ----------------------------------------
2025-11-27 15:04:17,095 [inflora.py] => Gradient Constraints Summary
2025-11-27 15:04:17,095 [inflora.py] => ----------------------------------------
2025-11-27 15:04:17,095 [inflora.py] => 1 layer constraint size: 7
2025-11-27 15:04:17,095 [inflora.py] => 2 layer constraint size: 13
2025-11-27 15:04:17,095 [inflora.py] => 3 layer constraint size: 18
2025-11-27 15:04:17,095 [inflora.py] => 4 layer constraint size: 21
2025-11-27 15:04:17,095 [inflora.py] => 5 layer constraint size: 25
2025-11-27 15:04:17,095 [inflora.py] => 6 layer constraint size: 31
2025-11-27 15:04:17,095 [inflora.py] => 7 layer constraint size: 31
2025-11-27 15:04:17,095 [inflora.py] => 8 layer constraint size: 42
2025-11-27 15:04:17,095 [inflora.py] => 9 layer constraint size: 46
2025-11-27 15:04:17,095 [inflora.py] => 10 layer constraint size: 46
2025-11-27 15:04:17,095 [inflora.py] => 11 layer constraint size: 19
2025-11-27 15:04:17,095 [inflora.py] => 12 layer constraint size: 42
2025-11-27 15:04:17,105 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:17,108 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:17,112 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:17,115 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:17,118 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:17,121 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:17,125 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:17,128 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:17,132 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:17,136 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:17,139 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:17,143 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:04:49,230 [inflora.py] => Exemplar size: 0
2025-11-27 15:04:49,231 [trainer.py] => No NME accuracy.
2025-11-27 15:04:49,231 [trainer.py] => CNN: {'total': np.float64(3.06), '00-09': np.float64(15.3), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), '40-49': np.float64(0.0), 'old': np.float64(3.82), 'new': np.float64(0.0)}
2025-11-27 15:04:49,231 [trainer.py] => CNN top1 curve: [np.float64(99.1), np.float64(6.5), np.float64(3.8), np.float64(1.42), np.float64(3.06)]
2025-11-27 15:04:49,231 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(17.1), np.float64(18.9), np.float64(13.55), np.float64(12.08)]

2025-11-27 15:04:49,231 [trainer.py] => Average Accuracy (CNN): 22.776 

2025-11-27 15:04:49,233 [trainer.py] => All params: 111194651
2025-11-27 15:04:49,235 [trainer.py] => Trainable params: 192010
2025-11-27 15:04:49,235 [inflora.py] => Learning on 50-60
2025-11-27 15:05:08,733 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_v.5.weight', 'image_encoder.blocks.5.attn.lora_B_v.5.weight', 'image_encoder.blocks.2.attn.lora_B_k.5.weight', 'image_encoder.blocks.6.attn.lora_B_v.5.weight', 'image_encoder.blocks.7.attn.lora_B_k.5.weight', 'image_encoder.blocks.8.attn.lora_B_k.5.weight', 'image_encoder.blocks.9.attn.lora_B_k.5.weight', 'image_encoder.blocks.8.attn.lora_B_v.5.weight', 'image_encoder.blocks.4.attn.lora_B_k.5.weight', 'image_encoder.blocks.11.attn.lora_B_k.5.weight', 'image_encoder.blocks.5.attn.lora_B_k.5.weight', 'image_encoder.blocks.3.attn.lora_B_v.5.weight', 'image_encoder.blocks.10.attn.lora_B_v.5.weight', 'classifier_pool.5.bias', 'image_encoder.blocks.1.attn.lora_B_k.5.weight', 'image_encoder.blocks.0.attn.lora_B_v.5.weight', 'image_encoder.blocks.2.attn.lora_B_v.5.weight', 'image_encoder.blocks.9.attn.lora_B_v.5.weight', 'image_encoder.blocks.4.attn.lora_B_v.5.weight', 'image_encoder.blocks.10.attn.lora_B_k.5.weight', 'image_encoder.blocks.7.attn.lora_B_v.5.weight', 'classifier_pool.5.weight', 'image_encoder.blocks.6.attn.lora_B_k.5.weight', 'image_encoder.blocks.3.attn.lora_B_k.5.weight', 'image_encoder.blocks.11.attn.lora_B_v.5.weight', 'image_encoder.blocks.0.attn.lora_B_k.5.weight'}
2025-11-27 15:06:16,341 [inflora.py] => Task 5, Epoch 2/2 => Loss 0.288, Train_accy 90.46
2025-11-27 15:06:34,113 [inflora.py] => Threshold: 0.975
2025-11-27 15:06:34,806 [inflora.py] => Skip Updating DualGPM for layer: 1
2025-11-27 15:06:40,165 [inflora.py] => ----------------------------------------
2025-11-27 15:06:40,165 [inflora.py] => Gradient Constraints Summary
2025-11-27 15:06:40,165 [inflora.py] => ----------------------------------------
2025-11-27 15:06:40,165 [inflora.py] => 1 layer constraint size: 7
2025-11-27 15:06:40,165 [inflora.py] => 2 layer constraint size: 14
2025-11-27 15:06:40,165 [inflora.py] => 3 layer constraint size: 20
2025-11-27 15:06:40,165 [inflora.py] => 4 layer constraint size: 24
2025-11-27 15:06:40,166 [inflora.py] => 5 layer constraint size: 32
2025-11-27 15:06:40,166 [inflora.py] => 6 layer constraint size: 40
2025-11-27 15:06:40,166 [inflora.py] => 7 layer constraint size: 42
2025-11-27 15:06:40,166 [inflora.py] => 8 layer constraint size: 56
2025-11-27 15:06:40,166 [inflora.py] => 9 layer constraint size: 57
2025-11-27 15:06:40,166 [inflora.py] => 10 layer constraint size: 56
2025-11-27 15:06:40,166 [inflora.py] => 11 layer constraint size: 25
2025-11-27 15:06:40,166 [inflora.py] => 12 layer constraint size: 49
2025-11-27 15:06:40,168 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:06:40,172 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:06:40,177 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:06:40,180 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:06:40,184 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:06:40,187 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:06:40,190 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:06:40,194 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:06:40,198 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:06:40,201 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:06:40,205 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:06:40,209 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:07:15,748 [inflora.py] => Exemplar size: 0
2025-11-27 15:07:15,749 [trainer.py] => No NME accuracy.
2025-11-27 15:07:15,749 [trainer.py] => CNN: {'total': np.float64(1.52), '00-09': np.float64(9.1), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), '40-49': np.float64(0.0), '50-59': np.float64(0.0), 'old': np.float64(1.82), 'new': np.float64(0.0)}
2025-11-27 15:07:15,749 [trainer.py] => CNN top1 curve: [np.float64(99.1), np.float64(6.5), np.float64(3.8), np.float64(1.42), np.float64(3.06), np.float64(1.52)]
2025-11-27 15:07:15,749 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(17.1), np.float64(18.9), np.float64(13.55), np.float64(12.08), np.float64(9.28)]

2025-11-27 15:07:15,749 [trainer.py] => Average Accuracy (CNN): 19.23333333333333 

2025-11-27 15:07:15,751 [trainer.py] => All params: 111194651
2025-11-27 15:07:15,753 [trainer.py] => Trainable params: 192010
2025-11-27 15:07:15,753 [inflora.py] => Learning on 60-70
2025-11-27 15:07:35,205 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.9.attn.lora_B_k.6.weight', 'image_encoder.blocks.6.attn.lora_B_v.6.weight', 'image_encoder.blocks.1.attn.lora_B_v.6.weight', 'image_encoder.blocks.2.attn.lora_B_v.6.weight', 'image_encoder.blocks.2.attn.lora_B_k.6.weight', 'image_encoder.blocks.11.attn.lora_B_k.6.weight', 'image_encoder.blocks.8.attn.lora_B_v.6.weight', 'classifier_pool.6.bias', 'image_encoder.blocks.3.attn.lora_B_v.6.weight', 'image_encoder.blocks.9.attn.lora_B_v.6.weight', 'classifier_pool.6.weight', 'image_encoder.blocks.0.attn.lora_B_v.6.weight', 'image_encoder.blocks.3.attn.lora_B_k.6.weight', 'image_encoder.blocks.6.attn.lora_B_k.6.weight', 'image_encoder.blocks.4.attn.lora_B_k.6.weight', 'image_encoder.blocks.10.attn.lora_B_v.6.weight', 'image_encoder.blocks.4.attn.lora_B_v.6.weight', 'image_encoder.blocks.7.attn.lora_B_v.6.weight', 'image_encoder.blocks.7.attn.lora_B_k.6.weight', 'image_encoder.blocks.10.attn.lora_B_k.6.weight', 'image_encoder.blocks.1.attn.lora_B_k.6.weight', 'image_encoder.blocks.5.attn.lora_B_v.6.weight', 'image_encoder.blocks.0.attn.lora_B_k.6.weight', 'image_encoder.blocks.8.attn.lora_B_k.6.weight', 'image_encoder.blocks.11.attn.lora_B_v.6.weight', 'image_encoder.blocks.5.attn.lora_B_k.6.weight'}
2025-11-27 15:08:43,067 [inflora.py] => Task 6, Epoch 2/2 => Loss 0.342, Train_accy 88.50
2025-11-27 15:09:00,431 [inflora.py] => Threshold: 0.98
2025-11-27 15:09:01,402 [inflora.py] => Skip Updating DualGPM for layer: 2
2025-11-27 15:09:06,003 [inflora.py] => ----------------------------------------
2025-11-27 15:09:06,004 [inflora.py] => Gradient Constraints Summary
2025-11-27 15:09:06,004 [inflora.py] => ----------------------------------------
2025-11-27 15:09:06,004 [inflora.py] => 1 layer constraint size: 8
2025-11-27 15:09:06,004 [inflora.py] => 2 layer constraint size: 14
2025-11-27 15:09:06,004 [inflora.py] => 3 layer constraint size: 21
2025-11-27 15:09:06,004 [inflora.py] => 4 layer constraint size: 27
2025-11-27 15:09:06,004 [inflora.py] => 5 layer constraint size: 35
2025-11-27 15:09:06,004 [inflora.py] => 6 layer constraint size: 46
2025-11-27 15:09:06,004 [inflora.py] => 7 layer constraint size: 53
2025-11-27 15:09:06,004 [inflora.py] => 8 layer constraint size: 72
2025-11-27 15:09:06,004 [inflora.py] => 9 layer constraint size: 80
2025-11-27 15:09:06,005 [inflora.py] => 10 layer constraint size: 80
2025-11-27 15:09:06,005 [inflora.py] => 11 layer constraint size: 37
2025-11-27 15:09:06,005 [inflora.py] => 12 layer constraint size: 62
2025-11-27 15:09:06,007 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:06,013 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:06,019 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:06,023 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:06,027 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:06,030 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:06,034 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:06,039 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:06,045 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:06,087 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:06,089 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:06,092 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:09:44,401 [inflora.py] => Exemplar size: 0
2025-11-27 15:09:44,401 [trainer.py] => No NME accuracy.
2025-11-27 15:09:44,402 [trainer.py] => CNN: {'total': np.float64(1.54), '00-09': np.float64(10.8), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), '40-49': np.float64(0.0), '50-59': np.float64(0.0), '60-69': np.float64(0.0), 'old': np.float64(1.8), 'new': np.float64(0.0)}
2025-11-27 15:09:44,402 [trainer.py] => CNN top1 curve: [np.float64(99.1), np.float64(6.5), np.float64(3.8), np.float64(1.42), np.float64(3.06), np.float64(1.52), np.float64(1.54)]
2025-11-27 15:09:44,402 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(17.1), np.float64(18.9), np.float64(13.55), np.float64(12.08), np.float64(9.28), np.float64(9.26)]

2025-11-27 15:09:44,402 [trainer.py] => Average Accuracy (CNN): 16.705714285714286 

2025-11-27 15:09:44,404 [trainer.py] => All params: 111194651
2025-11-27 15:09:44,406 [trainer.py] => Trainable params: 192010
2025-11-27 15:09:44,407 [inflora.py] => Learning on 70-80
2025-11-27 15:10:03,644 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.10.attn.lora_B_k.7.weight', 'image_encoder.blocks.1.attn.lora_B_k.7.weight', 'image_encoder.blocks.6.attn.lora_B_k.7.weight', 'image_encoder.blocks.2.attn.lora_B_k.7.weight', 'image_encoder.blocks.8.attn.lora_B_k.7.weight', 'image_encoder.blocks.5.attn.lora_B_k.7.weight', 'image_encoder.blocks.3.attn.lora_B_k.7.weight', 'image_encoder.blocks.11.attn.lora_B_k.7.weight', 'image_encoder.blocks.11.attn.lora_B_v.7.weight', 'image_encoder.blocks.4.attn.lora_B_k.7.weight', 'image_encoder.blocks.7.attn.lora_B_v.7.weight', 'image_encoder.blocks.5.attn.lora_B_v.7.weight', 'image_encoder.blocks.8.attn.lora_B_v.7.weight', 'image_encoder.blocks.0.attn.lora_B_v.7.weight', 'classifier_pool.7.weight', 'image_encoder.blocks.9.attn.lora_B_v.7.weight', 'image_encoder.blocks.7.attn.lora_B_k.7.weight', 'image_encoder.blocks.10.attn.lora_B_v.7.weight', 'image_encoder.blocks.2.attn.lora_B_v.7.weight', 'image_encoder.blocks.1.attn.lora_B_v.7.weight', 'image_encoder.blocks.0.attn.lora_B_k.7.weight', 'image_encoder.blocks.3.attn.lora_B_v.7.weight', 'image_encoder.blocks.9.attn.lora_B_k.7.weight', 'classifier_pool.7.bias', 'image_encoder.blocks.6.attn.lora_B_v.7.weight', 'image_encoder.blocks.4.attn.lora_B_v.7.weight'}
2025-11-27 15:11:13,967 [inflora.py] => Task 7, Epoch 2/2 => Loss 0.278, Train_accy 90.78
2025-11-27 15:11:31,793 [inflora.py] => Threshold: 0.985
2025-11-27 15:11:37,639 [inflora.py] => ----------------------------------------
2025-11-27 15:11:37,639 [inflora.py] => Gradient Constraints Summary
2025-11-27 15:11:37,639 [inflora.py] => ----------------------------------------
2025-11-27 15:11:37,639 [inflora.py] => 1 layer constraint size: 9
2025-11-27 15:11:37,639 [inflora.py] => 2 layer constraint size: 16
2025-11-27 15:11:37,639 [inflora.py] => 3 layer constraint size: 24
2025-11-27 15:11:37,639 [inflora.py] => 4 layer constraint size: 32
2025-11-27 15:11:37,639 [inflora.py] => 5 layer constraint size: 43
2025-11-27 15:11:37,639 [inflora.py] => 6 layer constraint size: 57
2025-11-27 15:11:37,640 [inflora.py] => 7 layer constraint size: 68
2025-11-27 15:11:37,640 [inflora.py] => 8 layer constraint size: 97
2025-11-27 15:11:37,640 [inflora.py] => 9 layer constraint size: 110
2025-11-27 15:11:37,640 [inflora.py] => 10 layer constraint size: 112
2025-11-27 15:11:37,640 [inflora.py] => 11 layer constraint size: 52
2025-11-27 15:11:37,640 [inflora.py] => 12 layer constraint size: 74
2025-11-27 15:11:37,643 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:11:37,649 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:11:37,653 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:11:37,657 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:11:37,663 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:11:37,667 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:11:37,674 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:11:37,680 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:11:37,687 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:11:37,694 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:11:37,723 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:11:37,726 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:12:19,253 [inflora.py] => Exemplar size: 0
2025-11-27 15:12:19,253 [trainer.py] => No NME accuracy.
2025-11-27 15:12:19,253 [trainer.py] => CNN: {'total': np.float64(3.06), '00-09': np.float64(24.5), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), '40-49': np.float64(0.0), '50-59': np.float64(0.0), '60-69': np.float64(0.0), '70-79': np.float64(0.0), 'old': np.float64(3.5), 'new': np.float64(0.0)}
2025-11-27 15:12:19,253 [trainer.py] => CNN top1 curve: [np.float64(99.1), np.float64(6.5), np.float64(3.8), np.float64(1.42), np.float64(3.06), np.float64(1.52), np.float64(1.54), np.float64(3.06)]
2025-11-27 15:12:19,253 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(17.1), np.float64(18.9), np.float64(13.55), np.float64(12.08), np.float64(9.28), np.float64(9.26), np.float64(7.34)]

2025-11-27 15:12:19,253 [trainer.py] => Average Accuracy (CNN): 15.0 

2025-11-27 15:12:19,256 [trainer.py] => All params: 111194651
2025-11-27 15:12:19,258 [trainer.py] => Trainable params: 192010
2025-11-27 15:12:19,258 [inflora.py] => Learning on 80-90
2025-11-27 15:12:57,138 [trainer.py] => config: exps/inflora_c100.json
2025-11-27 15:12:57,139 [trainer.py] => prefix: reproduce
2025-11-27 15:12:57,139 [trainer.py] => dataset: cifar224
2025-11-27 15:12:57,139 [trainer.py] => memory_size: 0
2025-11-27 15:12:57,139 [trainer.py] => memory_per_class: 0
2025-11-27 15:12:57,139 [trainer.py] => fixed_memory: True
2025-11-27 15:12:57,139 [trainer.py] => shuffle: False
2025-11-27 15:12:57,139 [trainer.py] => init_cls: 10
2025-11-27 15:12:57,139 [trainer.py] => increment: 10
2025-11-27 15:12:57,139 [trainer.py] => model_name: inflora
2025-11-27 15:12:57,139 [trainer.py] => net_type: sip
2025-11-27 15:12:57,139 [trainer.py] => backbone_type: vit_base_patch16_224
2025-11-27 15:12:57,140 [trainer.py] => pretrained: True
2025-11-27 15:12:57,140 [trainer.py] => embd_dim: 768
2025-11-27 15:12:57,140 [trainer.py] => num_heads: 12
2025-11-27 15:12:57,140 [trainer.py] => total_sessions: 10
2025-11-27 15:12:57,140 [trainer.py] => device: [device(type='cuda', index=0)]
2025-11-27 15:12:57,140 [trainer.py] => seed: 0
2025-11-27 15:12:57,140 [trainer.py] => EPSILON: 1e-08
2025-11-27 15:12:57,140 [trainer.py] => optim: adam
2025-11-27 15:12:57,140 [trainer.py] => init_epoch: 10
2025-11-27 15:12:57,140 [trainer.py] => init_lr: 0.0005
2025-11-27 15:12:57,140 [trainer.py] => init_lr_decay: 0.1
2025-11-27 15:12:57,140 [trainer.py] => init_weight_decay: 0.0
2025-11-27 15:12:57,140 [trainer.py] => epochs: 10
2025-11-27 15:12:57,140 [trainer.py] => lrate: 0.0005
2025-11-27 15:12:57,140 [trainer.py] => lrate_decay: 0.1
2025-11-27 15:12:57,140 [trainer.py] => batch_size: 128
2025-11-27 15:12:57,140 [trainer.py] => weight_decay: 0.0
2025-11-27 15:12:57,140 [trainer.py] => rank: 10
2025-11-27 15:12:57,140 [trainer.py] => lamb: 0.95
2025-11-27 15:12:57,140 [trainer.py] => lame: 1.0
2025-11-27 15:12:57,140 [trainer.py] => num_workers: 8
2025-11-27 15:13:01,559 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2025-11-27 15:13:04,651 [sinet_inflora.py] => Using vit_base_patch16_224_in21k instead of vit_base_patch16_224 for better pretrained weights
2025-11-27 15:13:04,651 [sinet_inflora.py] => Creating SiNet with variant=vit_base_patch16_224_in21k, pretrained=True
2025-11-27 15:13:06,204 [sinet_inflora.py] => Loading pretrained weights for vit_base_patch16_224_in21k using timm...
2025-11-27 15:13:07,339 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-11-27 15:13:07,697 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-11-27 15:13:08,680 [sinet_inflora.py] => Successfully loaded using direct import from timm.models.vision_transformer
2025-11-27 15:13:08,707 [sinet_inflora.py] => Missing keys (non-LoRA): ['cls_token_grow', 'pos_embed_grow', 'head.weight', 'head.bias']...
2025-11-27 15:13:08,708 [sinet_inflora.py] => Successfully loaded 150/150 pretrained weights for vit_base_patch16_224_in21k
2025-11-27 15:13:08,729 [trainer.py] => All params: 111194651
2025-11-27 15:13:08,732 [trainer.py] => Trainable params: 111194651
2025-11-27 15:13:08,732 [inflora.py] => Learning on 0-10
2025-11-27 15:13:30,442 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.5.attn.lora_B_v.0.weight', 'image_encoder.blocks.1.attn.lora_B_k.0.weight', 'image_encoder.blocks.7.attn.lora_B_k.0.weight', 'image_encoder.blocks.11.attn.lora_B_k.0.weight', 'image_encoder.blocks.3.attn.lora_B_k.0.weight', 'image_encoder.blocks.0.attn.lora_B_v.0.weight', 'image_encoder.blocks.3.attn.lora_B_v.0.weight', 'image_encoder.blocks.0.attn.lora_B_k.0.weight', 'image_encoder.blocks.2.attn.lora_B_v.0.weight', 'image_encoder.blocks.5.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_k.0.weight', 'classifier_pool.0.bias', 'image_encoder.blocks.4.attn.lora_B_k.0.weight', 'image_encoder.blocks.1.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_k.0.weight', 'image_encoder.blocks.8.attn.lora_B_v.0.weight', 'image_encoder.blocks.7.attn.lora_B_v.0.weight', 'image_encoder.blocks.8.attn.lora_B_k.0.weight', 'image_encoder.blocks.4.attn.lora_B_v.0.weight', 'image_encoder.blocks.2.attn.lora_B_k.0.weight', 'image_encoder.blocks.6.attn.lora_B_k.0.weight', 'image_encoder.blocks.10.attn.lora_B_v.0.weight', 'classifier_pool.0.weight', 'image_encoder.blocks.6.attn.lora_B_v.0.weight', 'image_encoder.blocks.11.attn.lora_B_v.0.weight', 'image_encoder.blocks.9.attn.lora_B_v.0.weight'}
2025-11-27 15:19:07,491 [inflora.py] => Task 0, Epoch 10/10 => Loss 0.169, Train_accy 94.58
2025-11-27 15:19:24,701 [inflora.py] => Threshold: 0.95
2025-11-27 15:19:27,723 [inflora.py] => ----------------------------------------
2025-11-27 15:19:27,725 [inflora.py] => Gradient Constraints Summary
2025-11-27 15:19:27,725 [inflora.py] => ----------------------------------------
2025-11-27 15:19:27,725 [inflora.py] => 1 layer constraint size: 6
2025-11-27 15:19:27,725 [inflora.py] => 2 layer constraint size: 9
2025-11-27 15:19:27,725 [inflora.py] => 3 layer constraint size: 11
2025-11-27 15:19:27,725 [inflora.py] => 4 layer constraint size: 10
2025-11-27 15:19:27,725 [inflora.py] => 5 layer constraint size: 12
2025-11-27 15:19:27,725 [inflora.py] => 6 layer constraint size: 13
2025-11-27 15:19:27,725 [inflora.py] => 7 layer constraint size: 12
2025-11-27 15:19:27,725 [inflora.py] => 8 layer constraint size: 17
2025-11-27 15:19:27,725 [inflora.py] => 9 layer constraint size: 17
2025-11-27 15:19:27,725 [inflora.py] => 10 layer constraint size: 14
2025-11-27 15:19:27,726 [inflora.py] => 11 layer constraint size: 5
2025-11-27 15:19:27,726 [inflora.py] => 12 layer constraint size: 9
2025-11-27 15:19:27,727 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:27,729 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:27,731 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:27,733 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:27,736 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:27,739 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:27,739 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:27,742 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:27,744 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:27,745 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:27,746 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:27,747 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:19:48,724 [inflora.py] => Exemplar size: 0
2025-11-27 15:19:48,724 [trainer.py] => No NME accuracy.
2025-11-27 15:19:48,724 [trainer.py] => CNN: {'total': np.float64(99.3), '00-09': np.float64(99.3), 'old': 0, 'new': np.float64(99.3)}
2025-11-27 15:19:48,724 [trainer.py] => CNN top1 curve: [np.float64(99.3)]
2025-11-27 15:19:48,724 [trainer.py] => CNN top5 curve: [np.float64(100.0)]

2025-11-27 15:19:48,724 [trainer.py] => Average Accuracy (CNN): 99.3 

2025-11-27 15:19:48,727 [trainer.py] => All params: 111194651
2025-11-27 15:19:48,729 [trainer.py] => Trainable params: 192010
2025-11-27 15:19:48,729 [inflora.py] => Learning on 10-20
2025-11-27 15:20:08,025 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.8.attn.lora_B_v.1.weight', 'image_encoder.blocks.6.attn.lora_B_v.1.weight', 'image_encoder.blocks.0.attn.lora_B_v.1.weight', 'image_encoder.blocks.5.attn.lora_B_k.1.weight', 'image_encoder.blocks.7.attn.lora_B_v.1.weight', 'image_encoder.blocks.7.attn.lora_B_k.1.weight', 'image_encoder.blocks.3.attn.lora_B_k.1.weight', 'image_encoder.blocks.3.attn.lora_B_v.1.weight', 'image_encoder.blocks.1.attn.lora_B_k.1.weight', 'image_encoder.blocks.0.attn.lora_B_k.1.weight', 'image_encoder.blocks.8.attn.lora_B_k.1.weight', 'image_encoder.blocks.9.attn.lora_B_k.1.weight', 'image_encoder.blocks.4.attn.lora_B_v.1.weight', 'image_encoder.blocks.1.attn.lora_B_v.1.weight', 'image_encoder.blocks.2.attn.lora_B_k.1.weight', 'image_encoder.blocks.4.attn.lora_B_k.1.weight', 'classifier_pool.1.bias', 'image_encoder.blocks.11.attn.lora_B_k.1.weight', 'image_encoder.blocks.6.attn.lora_B_k.1.weight', 'classifier_pool.1.weight', 'image_encoder.blocks.5.attn.lora_B_v.1.weight', 'image_encoder.blocks.11.attn.lora_B_v.1.weight', 'image_encoder.blocks.9.attn.lora_B_v.1.weight', 'image_encoder.blocks.10.attn.lora_B_k.1.weight', 'image_encoder.blocks.10.attn.lora_B_v.1.weight', 'image_encoder.blocks.2.attn.lora_B_v.1.weight'}
2025-11-27 15:25:48,360 [inflora.py] => Task 1, Epoch 10/10 => Loss 0.228, Train_accy 93.28
2025-11-27 15:26:06,393 [inflora.py] => Threshold: 0.955
2025-11-27 15:26:12,319 [inflora.py] => ----------------------------------------
2025-11-27 15:26:12,319 [inflora.py] => Gradient Constraints Summary
2025-11-27 15:26:12,320 [inflora.py] => ----------------------------------------
2025-11-27 15:26:12,320 [inflora.py] => 1 layer constraint size: 7
2025-11-27 15:26:12,320 [inflora.py] => 2 layer constraint size: 10
2025-11-27 15:26:12,320 [inflora.py] => 3 layer constraint size: 14
2025-11-27 15:26:12,320 [inflora.py] => 4 layer constraint size: 13
2025-11-27 15:26:12,320 [inflora.py] => 5 layer constraint size: 18
2025-11-27 15:26:12,320 [inflora.py] => 6 layer constraint size: 21
2025-11-27 15:26:12,320 [inflora.py] => 7 layer constraint size: 20
2025-11-27 15:26:12,320 [inflora.py] => 8 layer constraint size: 27
2025-11-27 15:26:12,320 [inflora.py] => 9 layer constraint size: 35
2025-11-27 15:26:12,320 [inflora.py] => 10 layer constraint size: 34
2025-11-27 15:26:12,321 [inflora.py] => 11 layer constraint size: 11
2025-11-27 15:26:12,321 [inflora.py] => 12 layer constraint size: 22
2025-11-27 15:26:12,324 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:12,329 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:12,337 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:12,342 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:12,347 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:12,354 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:12,361 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:12,367 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:12,370 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:12,374 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:12,376 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:12,378 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:26:35,293 [inflora.py] => Exemplar size: 0
2025-11-27 15:26:35,294 [trainer.py] => No NME accuracy.
2025-11-27 15:26:35,297 [trainer.py] => CNN: {'total': np.float64(7.2), '00-09': np.float64(14.4), '10-19': np.float64(0.0), 'old': np.float64(14.4), 'new': np.float64(0.0)}
2025-11-27 15:26:35,298 [trainer.py] => CNN top1 curve: [np.float64(99.3), np.float64(7.2)]
2025-11-27 15:26:35,298 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(18.65)]

2025-11-27 15:26:35,298 [trainer.py] => Average Accuracy (CNN): 53.25 

2025-11-27 15:26:35,303 [trainer.py] => All params: 111194651
2025-11-27 15:26:35,305 [trainer.py] => Trainable params: 192010
2025-11-27 15:26:35,305 [inflora.py] => Learning on 20-30
2025-11-27 15:26:54,463 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.3.attn.lora_B_k.2.weight', 'classifier_pool.2.weight', 'image_encoder.blocks.0.attn.lora_B_v.2.weight', 'image_encoder.blocks.5.attn.lora_B_v.2.weight', 'image_encoder.blocks.7.attn.lora_B_v.2.weight', 'image_encoder.blocks.7.attn.lora_B_k.2.weight', 'image_encoder.blocks.2.attn.lora_B_k.2.weight', 'image_encoder.blocks.10.attn.lora_B_v.2.weight', 'image_encoder.blocks.4.attn.lora_B_k.2.weight', 'image_encoder.blocks.11.attn.lora_B_v.2.weight', 'image_encoder.blocks.8.attn.lora_B_k.2.weight', 'image_encoder.blocks.9.attn.lora_B_v.2.weight', 'image_encoder.blocks.4.attn.lora_B_v.2.weight', 'image_encoder.blocks.2.attn.lora_B_v.2.weight', 'image_encoder.blocks.10.attn.lora_B_k.2.weight', 'image_encoder.blocks.0.attn.lora_B_k.2.weight', 'image_encoder.blocks.8.attn.lora_B_v.2.weight', 'image_encoder.blocks.9.attn.lora_B_k.2.weight', 'image_encoder.blocks.6.attn.lora_B_k.2.weight', 'image_encoder.blocks.5.attn.lora_B_k.2.weight', 'image_encoder.blocks.3.attn.lora_B_v.2.weight', 'image_encoder.blocks.1.attn.lora_B_k.2.weight', 'image_encoder.blocks.6.attn.lora_B_v.2.weight', 'image_encoder.blocks.11.attn.lora_B_k.2.weight', 'image_encoder.blocks.1.attn.lora_B_v.2.weight', 'classifier_pool.2.bias'}
2025-11-27 15:33:07,515 [inflora.py] => Task 2, Epoch 10/10 => Loss 0.188, Train_accy 93.62
2025-11-27 15:33:25,260 [inflora.py] => Threshold: 0.96
2025-11-27 15:33:25,736 [inflora.py] => Skip Updating DualGPM for layer: 1
2025-11-27 15:33:30,867 [inflora.py] => ----------------------------------------
2025-11-27 15:33:30,867 [inflora.py] => Gradient Constraints Summary
2025-11-27 15:33:30,867 [inflora.py] => ----------------------------------------
2025-11-27 15:33:30,867 [inflora.py] => 1 layer constraint size: 7
2025-11-27 15:33:30,867 [inflora.py] => 2 layer constraint size: 11
2025-11-27 15:33:30,867 [inflora.py] => 3 layer constraint size: 15
2025-11-27 15:33:30,867 [inflora.py] => 4 layer constraint size: 15
2025-11-27 15:33:30,867 [inflora.py] => 5 layer constraint size: 21
2025-11-27 15:33:30,867 [inflora.py] => 6 layer constraint size: 25
2025-11-27 15:33:30,867 [inflora.py] => 7 layer constraint size: 27
2025-11-27 15:33:30,868 [inflora.py] => 8 layer constraint size: 38
2025-11-27 15:33:30,868 [inflora.py] => 9 layer constraint size: 53
2025-11-27 15:33:30,868 [inflora.py] => 10 layer constraint size: 48
2025-11-27 15:33:30,868 [inflora.py] => 11 layer constraint size: 17
2025-11-27 15:33:30,868 [inflora.py] => 12 layer constraint size: 31
2025-11-27 15:33:30,871 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:30,886 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:30,912 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:30,919 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:30,925 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:30,949 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:30,961 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:30,970 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:30,988 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:30,994 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:30,996 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:30,998 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:33:56,894 [inflora.py] => Exemplar size: 0
2025-11-27 15:33:56,894 [trainer.py] => No NME accuracy.
2025-11-27 15:33:56,898 [trainer.py] => CNN: {'total': np.float64(4.37), '00-09': np.float64(13.1), '10-19': np.float64(0.0), '20-29': np.float64(0.0), 'old': np.float64(6.55), 'new': np.float64(0.0)}
2025-11-27 15:33:56,898 [trainer.py] => CNN top1 curve: [np.float64(99.3), np.float64(7.2), np.float64(4.37)]
2025-11-27 15:33:56,898 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(18.65), np.float64(20.2)]

2025-11-27 15:33:56,900 [trainer.py] => Average Accuracy (CNN): 36.95666666666667 

2025-11-27 15:33:56,904 [trainer.py] => All params: 111194651
2025-11-27 15:33:56,906 [trainer.py] => Trainable params: 192010
2025-11-27 15:33:56,906 [inflora.py] => Learning on 30-40
2025-11-27 15:34:16,337 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.2.attn.lora_B_k.3.weight', 'image_encoder.blocks.1.attn.lora_B_v.3.weight', 'image_encoder.blocks.2.attn.lora_B_v.3.weight', 'classifier_pool.3.weight', 'classifier_pool.3.bias', 'image_encoder.blocks.8.attn.lora_B_v.3.weight', 'image_encoder.blocks.11.attn.lora_B_v.3.weight', 'image_encoder.blocks.0.attn.lora_B_k.3.weight', 'image_encoder.blocks.4.attn.lora_B_k.3.weight', 'image_encoder.blocks.1.attn.lora_B_k.3.weight', 'image_encoder.blocks.8.attn.lora_B_k.3.weight', 'image_encoder.blocks.5.attn.lora_B_v.3.weight', 'image_encoder.blocks.4.attn.lora_B_v.3.weight', 'image_encoder.blocks.7.attn.lora_B_k.3.weight', 'image_encoder.blocks.11.attn.lora_B_k.3.weight', 'image_encoder.blocks.7.attn.lora_B_v.3.weight', 'image_encoder.blocks.9.attn.lora_B_k.3.weight', 'image_encoder.blocks.6.attn.lora_B_k.3.weight', 'image_encoder.blocks.6.attn.lora_B_v.3.weight', 'image_encoder.blocks.5.attn.lora_B_k.3.weight', 'image_encoder.blocks.9.attn.lora_B_v.3.weight', 'image_encoder.blocks.3.attn.lora_B_k.3.weight', 'image_encoder.blocks.10.attn.lora_B_v.3.weight', 'image_encoder.blocks.3.attn.lora_B_v.3.weight', 'image_encoder.blocks.0.attn.lora_B_v.3.weight', 'image_encoder.blocks.10.attn.lora_B_k.3.weight'}
2025-11-27 15:39:53,957 [inflora.py] => Task 3, Epoch 10/10 => Loss 0.178, Train_accy 94.10
2025-11-27 15:40:11,987 [inflora.py] => Threshold: 0.965
2025-11-27 15:40:12,764 [inflora.py] => Skip Updating DualGPM for layer: 1
2025-11-27 15:40:18,277 [inflora.py] => ----------------------------------------
2025-11-27 15:40:18,277 [inflora.py] => Gradient Constraints Summary
2025-11-27 15:40:18,277 [inflora.py] => ----------------------------------------
2025-11-27 15:40:18,277 [inflora.py] => 1 layer constraint size: 7
2025-11-27 15:40:18,277 [inflora.py] => 2 layer constraint size: 12
2025-11-27 15:40:18,278 [inflora.py] => 3 layer constraint size: 17
2025-11-27 15:40:18,278 [inflora.py] => 4 layer constraint size: 18
2025-11-27 15:40:18,278 [inflora.py] => 5 layer constraint size: 24
2025-11-27 15:40:18,278 [inflora.py] => 6 layer constraint size: 31
2025-11-27 15:40:18,278 [inflora.py] => 7 layer constraint size: 33
2025-11-27 15:40:18,278 [inflora.py] => 8 layer constraint size: 49
2025-11-27 15:40:18,278 [inflora.py] => 9 layer constraint size: 71
2025-11-27 15:40:18,278 [inflora.py] => 10 layer constraint size: 72
2025-11-27 15:40:18,278 [inflora.py] => 11 layer constraint size: 27
2025-11-27 15:40:18,278 [inflora.py] => 12 layer constraint size: 40
2025-11-27 15:40:18,281 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:18,284 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:18,289 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:18,293 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:18,302 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:18,308 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:18,312 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:18,315 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:18,319 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:18,323 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:18,325 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:18,327 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:40:47,260 [inflora.py] => Exemplar size: 0
2025-11-27 15:40:47,261 [trainer.py] => No NME accuracy.
2025-11-27 15:40:47,261 [trainer.py] => CNN: {'total': np.float64(1.23), '00-09': np.float64(4.9), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), 'old': np.float64(1.63), 'new': np.float64(0.0)}
2025-11-27 15:40:47,261 [trainer.py] => CNN top1 curve: [np.float64(99.3), np.float64(7.2), np.float64(4.37), np.float64(1.23)]
2025-11-27 15:40:47,261 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(18.65), np.float64(20.2), np.float64(12.85)]

2025-11-27 15:40:47,261 [trainer.py] => Average Accuracy (CNN): 28.025000000000002 

2025-11-27 15:40:47,264 [trainer.py] => All params: 111194651
2025-11-27 15:40:47,266 [trainer.py] => Trainable params: 192010
2025-11-27 15:40:47,266 [inflora.py] => Learning on 40-50
2025-11-27 15:41:06,664 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_v.4.weight', 'image_encoder.blocks.6.attn.lora_B_k.4.weight', 'image_encoder.blocks.9.attn.lora_B_v.4.weight', 'image_encoder.blocks.10.attn.lora_B_k.4.weight', 'image_encoder.blocks.11.attn.lora_B_k.4.weight', 'image_encoder.blocks.5.attn.lora_B_v.4.weight', 'image_encoder.blocks.2.attn.lora_B_k.4.weight', 'image_encoder.blocks.6.attn.lora_B_v.4.weight', 'classifier_pool.4.weight', 'classifier_pool.4.bias', 'image_encoder.blocks.9.attn.lora_B_k.4.weight', 'image_encoder.blocks.10.attn.lora_B_v.4.weight', 'image_encoder.blocks.2.attn.lora_B_v.4.weight', 'image_encoder.blocks.11.attn.lora_B_v.4.weight', 'image_encoder.blocks.7.attn.lora_B_v.4.weight', 'image_encoder.blocks.4.attn.lora_B_v.4.weight', 'image_encoder.blocks.7.attn.lora_B_k.4.weight', 'image_encoder.blocks.4.attn.lora_B_k.4.weight', 'image_encoder.blocks.0.attn.lora_B_k.4.weight', 'image_encoder.blocks.5.attn.lora_B_k.4.weight', 'image_encoder.blocks.8.attn.lora_B_v.4.weight', 'image_encoder.blocks.0.attn.lora_B_v.4.weight', 'image_encoder.blocks.3.attn.lora_B_k.4.weight', 'image_encoder.blocks.1.attn.lora_B_k.4.weight', 'image_encoder.blocks.3.attn.lora_B_v.4.weight', 'image_encoder.blocks.8.attn.lora_B_k.4.weight'}
2025-11-27 15:46:45,419 [inflora.py] => Task 4, Epoch 10/10 => Loss 0.153, Train_accy 94.82
2025-11-27 15:47:03,121 [inflora.py] => Threshold: 0.97
2025-11-27 15:47:03,619 [inflora.py] => Skip Updating DualGPM for layer: 1
2025-11-27 15:47:04,056 [inflora.py] => Skip Updating DualGPM for layer: 2
2025-11-27 15:47:08,835 [inflora.py] => ----------------------------------------
2025-11-27 15:47:08,835 [inflora.py] => Gradient Constraints Summary
2025-11-27 15:47:08,835 [inflora.py] => ----------------------------------------
2025-11-27 15:47:08,835 [inflora.py] => 1 layer constraint size: 7
2025-11-27 15:47:08,835 [inflora.py] => 2 layer constraint size: 12
2025-11-27 15:47:08,836 [inflora.py] => 3 layer constraint size: 19
2025-11-27 15:47:08,836 [inflora.py] => 4 layer constraint size: 21
2025-11-27 15:47:08,836 [inflora.py] => 5 layer constraint size: 28
2025-11-27 15:47:08,836 [inflora.py] => 6 layer constraint size: 36
2025-11-27 15:47:08,836 [inflora.py] => 7 layer constraint size: 38
2025-11-27 15:47:08,836 [inflora.py] => 8 layer constraint size: 55
2025-11-27 15:47:08,836 [inflora.py] => 9 layer constraint size: 78
2025-11-27 15:47:08,836 [inflora.py] => 10 layer constraint size: 81
2025-11-27 15:47:08,836 [inflora.py] => 11 layer constraint size: 33
2025-11-27 15:47:08,836 [inflora.py] => 12 layer constraint size: 50
2025-11-27 15:47:08,839 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:08,849 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:08,855 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:08,858 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:08,863 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:08,869 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:08,875 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:08,881 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:08,888 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:08,895 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:08,900 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:08,902 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:47:40,767 [inflora.py] => Exemplar size: 0
2025-11-27 15:47:40,767 [trainer.py] => No NME accuracy.
2025-11-27 15:47:40,767 [trainer.py] => CNN: {'total': np.float64(2.36), '00-09': np.float64(11.8), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), '40-49': np.float64(0.0), 'old': np.float64(2.95), 'new': np.float64(0.0)}
2025-11-27 15:47:40,767 [trainer.py] => CNN top1 curve: [np.float64(99.3), np.float64(7.2), np.float64(4.37), np.float64(1.23), np.float64(2.36)]
2025-11-27 15:47:40,767 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(18.65), np.float64(20.2), np.float64(12.85), np.float64(12.42)]

2025-11-27 15:47:40,767 [trainer.py] => Average Accuracy (CNN): 22.892000000000003 

2025-11-27 15:47:40,773 [trainer.py] => All params: 111194651
2025-11-27 15:47:40,775 [trainer.py] => Trainable params: 192010
2025-11-27 15:47:40,775 [inflora.py] => Learning on 50-60
2025-11-27 15:48:02,742 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.7.attn.lora_B_k.5.weight', 'image_encoder.blocks.8.attn.lora_B_k.5.weight', 'image_encoder.blocks.0.attn.lora_B_v.5.weight', 'image_encoder.blocks.1.attn.lora_B_k.5.weight', 'image_encoder.blocks.2.attn.lora_B_k.5.weight', 'image_encoder.blocks.9.attn.lora_B_v.5.weight', 'image_encoder.blocks.10.attn.lora_B_k.5.weight', 'image_encoder.blocks.1.attn.lora_B_v.5.weight', 'image_encoder.blocks.5.attn.lora_B_k.5.weight', 'image_encoder.blocks.6.attn.lora_B_v.5.weight', 'image_encoder.blocks.11.attn.lora_B_k.5.weight', 'image_encoder.blocks.6.attn.lora_B_k.5.weight', 'image_encoder.blocks.10.attn.lora_B_v.5.weight', 'image_encoder.blocks.5.attn.lora_B_v.5.weight', 'classifier_pool.5.weight', 'image_encoder.blocks.4.attn.lora_B_k.5.weight', 'image_encoder.blocks.11.attn.lora_B_v.5.weight', 'image_encoder.blocks.8.attn.lora_B_v.5.weight', 'image_encoder.blocks.7.attn.lora_B_v.5.weight', 'image_encoder.blocks.2.attn.lora_B_v.5.weight', 'classifier_pool.5.bias', 'image_encoder.blocks.3.attn.lora_B_k.5.weight', 'image_encoder.blocks.0.attn.lora_B_k.5.weight', 'image_encoder.blocks.4.attn.lora_B_v.5.weight', 'image_encoder.blocks.3.attn.lora_B_v.5.weight', 'image_encoder.blocks.9.attn.lora_B_k.5.weight'}
2025-11-27 15:53:42,334 [inflora.py] => Task 5, Epoch 10/10 => Loss 0.198, Train_accy 93.20
2025-11-27 15:54:00,157 [inflora.py] => Threshold: 0.975
2025-11-27 15:54:00,652 [inflora.py] => Skip Updating DualGPM for layer: 1
2025-11-27 15:54:06,009 [inflora.py] => ----------------------------------------
2025-11-27 15:54:06,010 [inflora.py] => Gradient Constraints Summary
2025-11-27 15:54:06,010 [inflora.py] => ----------------------------------------
2025-11-27 15:54:06,010 [inflora.py] => 1 layer constraint size: 7
2025-11-27 15:54:06,010 [inflora.py] => 2 layer constraint size: 13
2025-11-27 15:54:06,010 [inflora.py] => 3 layer constraint size: 21
2025-11-27 15:54:06,010 [inflora.py] => 4 layer constraint size: 25
2025-11-27 15:54:06,010 [inflora.py] => 5 layer constraint size: 34
2025-11-27 15:54:06,010 [inflora.py] => 6 layer constraint size: 44
2025-11-27 15:54:06,010 [inflora.py] => 7 layer constraint size: 49
2025-11-27 15:54:06,011 [inflora.py] => 8 layer constraint size: 74
2025-11-27 15:54:06,011 [inflora.py] => 9 layer constraint size: 99
2025-11-27 15:54:06,011 [inflora.py] => 10 layer constraint size: 100
2025-11-27 15:54:06,011 [inflora.py] => 11 layer constraint size: 42
2025-11-27 15:54:06,011 [inflora.py] => 12 layer constraint size: 59
2025-11-27 15:54:06,015 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:06,023 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:06,027 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:06,034 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:06,037 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:06,041 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:06,048 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:06,053 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:06,059 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:06,067 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:06,075 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:06,077 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 15:54:40,960 [inflora.py] => Exemplar size: 0
2025-11-27 15:54:40,960 [trainer.py] => No NME accuracy.
2025-11-27 15:54:40,963 [trainer.py] => CNN: {'total': np.float64(1.47), '00-09': np.float64(8.8), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), '40-49': np.float64(0.0), '50-59': np.float64(0.0), 'old': np.float64(1.76), 'new': np.float64(0.0)}
2025-11-27 15:54:40,963 [trainer.py] => CNN top1 curve: [np.float64(99.3), np.float64(7.2), np.float64(4.37), np.float64(1.23), np.float64(2.36), np.float64(1.47)]
2025-11-27 15:54:40,963 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(18.65), np.float64(20.2), np.float64(12.85), np.float64(12.42), np.float64(9.73)]

2025-11-27 15:54:40,966 [trainer.py] => Average Accuracy (CNN): 19.32166666666667 

2025-11-27 15:54:40,968 [trainer.py] => All params: 111194651
2025-11-27 15:54:40,970 [trainer.py] => Trainable params: 192010
2025-11-27 15:54:40,971 [inflora.py] => Learning on 60-70
2025-11-27 15:55:00,078 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.1.attn.lora_B_v.6.weight', 'image_encoder.blocks.1.attn.lora_B_k.6.weight', 'image_encoder.blocks.2.attn.lora_B_v.6.weight', 'image_encoder.blocks.4.attn.lora_B_v.6.weight', 'image_encoder.blocks.5.attn.lora_B_v.6.weight', 'image_encoder.blocks.9.attn.lora_B_v.6.weight', 'image_encoder.blocks.7.attn.lora_B_k.6.weight', 'classifier_pool.6.bias', 'image_encoder.blocks.6.attn.lora_B_k.6.weight', 'image_encoder.blocks.0.attn.lora_B_v.6.weight', 'image_encoder.blocks.9.attn.lora_B_k.6.weight', 'image_encoder.blocks.7.attn.lora_B_v.6.weight', 'image_encoder.blocks.0.attn.lora_B_k.6.weight', 'image_encoder.blocks.4.attn.lora_B_k.6.weight', 'image_encoder.blocks.3.attn.lora_B_k.6.weight', 'image_encoder.blocks.2.attn.lora_B_k.6.weight', 'image_encoder.blocks.11.attn.lora_B_k.6.weight', 'classifier_pool.6.weight', 'image_encoder.blocks.6.attn.lora_B_v.6.weight', 'image_encoder.blocks.3.attn.lora_B_v.6.weight', 'image_encoder.blocks.11.attn.lora_B_v.6.weight', 'image_encoder.blocks.10.attn.lora_B_k.6.weight', 'image_encoder.blocks.8.attn.lora_B_k.6.weight', 'image_encoder.blocks.5.attn.lora_B_k.6.weight', 'image_encoder.blocks.8.attn.lora_B_v.6.weight', 'image_encoder.blocks.10.attn.lora_B_v.6.weight'}
2025-11-27 16:00:40,713 [inflora.py] => Task 6, Epoch 10/10 => Loss 0.202, Train_accy 93.38
2025-11-27 16:00:58,870 [inflora.py] => Threshold: 0.98
2025-11-27 16:01:04,440 [inflora.py] => ----------------------------------------
2025-11-27 16:01:04,441 [inflora.py] => Gradient Constraints Summary
2025-11-27 16:01:04,441 [inflora.py] => ----------------------------------------
2025-11-27 16:01:04,441 [inflora.py] => 1 layer constraint size: 8
2025-11-27 16:01:04,441 [inflora.py] => 2 layer constraint size: 14
2025-11-27 16:01:04,441 [inflora.py] => 3 layer constraint size: 22
2025-11-27 16:01:04,441 [inflora.py] => 4 layer constraint size: 28
2025-11-27 16:01:04,441 [inflora.py] => 5 layer constraint size: 39
2025-11-27 16:01:04,441 [inflora.py] => 6 layer constraint size: 52
2025-11-27 16:01:04,441 [inflora.py] => 7 layer constraint size: 62
2025-11-27 16:01:04,441 [inflora.py] => 8 layer constraint size: 92
2025-11-27 16:01:04,441 [inflora.py] => 9 layer constraint size: 128
2025-11-27 16:01:04,441 [inflora.py] => 10 layer constraint size: 134
2025-11-27 16:01:04,441 [inflora.py] => 11 layer constraint size: 63
2025-11-27 16:01:04,442 [inflora.py] => 12 layer constraint size: 78
2025-11-27 16:01:04,444 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:04,457 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:04,464 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:04,475 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:04,480 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:04,486 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:04,492 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:04,498 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:04,505 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:04,511 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:04,516 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:04,519 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:01:42,883 [inflora.py] => Exemplar size: 0
2025-11-27 16:01:42,884 [trainer.py] => No NME accuracy.
2025-11-27 16:01:42,884 [trainer.py] => CNN: {'total': np.float64(2.44), '00-09': np.float64(17.1), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), '40-49': np.float64(0.0), '50-59': np.float64(0.0), '60-69': np.float64(0.0), 'old': np.float64(2.85), 'new': np.float64(0.0)}
2025-11-27 16:01:42,884 [trainer.py] => CNN top1 curve: [np.float64(99.3), np.float64(7.2), np.float64(4.37), np.float64(1.23), np.float64(2.36), np.float64(1.47), np.float64(2.44)]
2025-11-27 16:01:42,884 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(18.65), np.float64(20.2), np.float64(12.85), np.float64(12.42), np.float64(9.73), np.float64(9.27)]

2025-11-27 16:01:42,884 [trainer.py] => Average Accuracy (CNN): 16.91 

2025-11-27 16:01:42,886 [trainer.py] => All params: 111194651
2025-11-27 16:01:42,889 [trainer.py] => Trainable params: 192010
2025-11-27 16:01:42,890 [inflora.py] => Learning on 70-80
2025-11-27 16:02:05,187 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.10.attn.lora_B_k.7.weight', 'image_encoder.blocks.8.attn.lora_B_k.7.weight', 'image_encoder.blocks.6.attn.lora_B_v.7.weight', 'image_encoder.blocks.8.attn.lora_B_v.7.weight', 'image_encoder.blocks.11.attn.lora_B_k.7.weight', 'image_encoder.blocks.3.attn.lora_B_v.7.weight', 'image_encoder.blocks.2.attn.lora_B_v.7.weight', 'image_encoder.blocks.7.attn.lora_B_v.7.weight', 'image_encoder.blocks.7.attn.lora_B_k.7.weight', 'image_encoder.blocks.4.attn.lora_B_k.7.weight', 'image_encoder.blocks.6.attn.lora_B_k.7.weight', 'image_encoder.blocks.5.attn.lora_B_k.7.weight', 'image_encoder.blocks.9.attn.lora_B_v.7.weight', 'image_encoder.blocks.0.attn.lora_B_v.7.weight', 'image_encoder.blocks.9.attn.lora_B_k.7.weight', 'classifier_pool.7.bias', 'image_encoder.blocks.10.attn.lora_B_v.7.weight', 'image_encoder.blocks.5.attn.lora_B_v.7.weight', 'image_encoder.blocks.1.attn.lora_B_k.7.weight', 'classifier_pool.7.weight', 'image_encoder.blocks.2.attn.lora_B_k.7.weight', 'image_encoder.blocks.11.attn.lora_B_v.7.weight', 'image_encoder.blocks.1.attn.lora_B_v.7.weight', 'image_encoder.blocks.4.attn.lora_B_v.7.weight', 'image_encoder.blocks.0.attn.lora_B_k.7.weight', 'image_encoder.blocks.3.attn.lora_B_k.7.weight'}
2025-11-27 16:07:47,845 [inflora.py] => Task 7, Epoch 10/10 => Loss 0.178, Train_accy 94.02
2025-11-27 16:08:06,411 [inflora.py] => Threshold: 0.985
2025-11-27 16:08:12,089 [inflora.py] => ----------------------------------------
2025-11-27 16:08:12,090 [inflora.py] => Gradient Constraints Summary
2025-11-27 16:08:12,090 [inflora.py] => ----------------------------------------
2025-11-27 16:08:12,090 [inflora.py] => 1 layer constraint size: 9
2025-11-27 16:08:12,090 [inflora.py] => 2 layer constraint size: 16
2025-11-27 16:08:12,090 [inflora.py] => 3 layer constraint size: 27
2025-11-27 16:08:12,090 [inflora.py] => 4 layer constraint size: 35
2025-11-27 16:08:12,090 [inflora.py] => 5 layer constraint size: 48
2025-11-27 16:08:12,090 [inflora.py] => 6 layer constraint size: 66
2025-11-27 16:08:12,090 [inflora.py] => 7 layer constraint size: 80
2025-11-27 16:08:12,090 [inflora.py] => 8 layer constraint size: 125
2025-11-27 16:08:12,090 [inflora.py] => 9 layer constraint size: 172
2025-11-27 16:08:12,090 [inflora.py] => 10 layer constraint size: 184
2025-11-27 16:08:12,090 [inflora.py] => 11 layer constraint size: 87
2025-11-27 16:08:12,091 [inflora.py] => 12 layer constraint size: 99
2025-11-27 16:08:12,094 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:12,102 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:12,108 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:12,112 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:12,117 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:12,123 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:12,128 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:12,134 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:12,141 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:12,148 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:12,152 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:12,155 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:08:53,395 [inflora.py] => Exemplar size: 0
2025-11-27 16:08:53,395 [trainer.py] => No NME accuracy.
2025-11-27 16:08:53,396 [trainer.py] => CNN: {'total': np.float64(3.29), '00-09': np.float64(26.3), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), '40-49': np.float64(0.0), '50-59': np.float64(0.0), '60-69': np.float64(0.0), '70-79': np.float64(0.0), 'old': np.float64(3.76), 'new': np.float64(0.0)}
2025-11-27 16:08:53,396 [trainer.py] => CNN top1 curve: [np.float64(99.3), np.float64(7.2), np.float64(4.37), np.float64(1.23), np.float64(2.36), np.float64(1.47), np.float64(2.44), np.float64(3.29)]
2025-11-27 16:08:53,396 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(18.65), np.float64(20.2), np.float64(12.85), np.float64(12.42), np.float64(9.73), np.float64(9.27), np.float64(7.26)]

2025-11-27 16:08:53,396 [trainer.py] => Average Accuracy (CNN): 15.207500000000001 

2025-11-27 16:08:53,398 [trainer.py] => All params: 111194651
2025-11-27 16:08:53,400 [trainer.py] => Trainable params: 192010
2025-11-27 16:08:53,400 [inflora.py] => Learning on 80-90
2025-11-27 16:09:12,727 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.0.attn.lora_B_k.8.weight', 'image_encoder.blocks.11.attn.lora_B_v.8.weight', 'image_encoder.blocks.5.attn.lora_B_v.8.weight', 'image_encoder.blocks.10.attn.lora_B_v.8.weight', 'image_encoder.blocks.6.attn.lora_B_k.8.weight', 'classifier_pool.8.bias', 'image_encoder.blocks.7.attn.lora_B_k.8.weight', 'image_encoder.blocks.4.attn.lora_B_v.8.weight', 'image_encoder.blocks.6.attn.lora_B_v.8.weight', 'classifier_pool.8.weight', 'image_encoder.blocks.3.attn.lora_B_v.8.weight', 'image_encoder.blocks.9.attn.lora_B_v.8.weight', 'image_encoder.blocks.4.attn.lora_B_k.8.weight', 'image_encoder.blocks.11.attn.lora_B_k.8.weight', 'image_encoder.blocks.9.attn.lora_B_k.8.weight', 'image_encoder.blocks.1.attn.lora_B_k.8.weight', 'image_encoder.blocks.5.attn.lora_B_k.8.weight', 'image_encoder.blocks.10.attn.lora_B_k.8.weight', 'image_encoder.blocks.8.attn.lora_B_k.8.weight', 'image_encoder.blocks.2.attn.lora_B_v.8.weight', 'image_encoder.blocks.8.attn.lora_B_v.8.weight', 'image_encoder.blocks.3.attn.lora_B_k.8.weight', 'image_encoder.blocks.1.attn.lora_B_v.8.weight', 'image_encoder.blocks.7.attn.lora_B_v.8.weight', 'image_encoder.blocks.0.attn.lora_B_v.8.weight', 'image_encoder.blocks.2.attn.lora_B_k.8.weight'}
2025-11-27 16:14:56,536 [inflora.py] => Task 8, Epoch 10/10 => Loss 0.163, Train_accy 94.78
2025-11-27 16:15:14,322 [inflora.py] => Threshold: 0.99
2025-11-27 16:15:14,932 [inflora.py] => Skip Updating DualGPM for layer: 1
2025-11-27 16:15:20,008 [inflora.py] => ----------------------------------------
2025-11-27 16:15:20,008 [inflora.py] => Gradient Constraints Summary
2025-11-27 16:15:20,009 [inflora.py] => ----------------------------------------
2025-11-27 16:15:20,009 [inflora.py] => 1 layer constraint size: 9
2025-11-27 16:15:20,009 [inflora.py] => 2 layer constraint size: 19
2025-11-27 16:15:20,009 [inflora.py] => 3 layer constraint size: 36
2025-11-27 16:15:20,009 [inflora.py] => 4 layer constraint size: 45
2025-11-27 16:15:20,009 [inflora.py] => 5 layer constraint size: 63
2025-11-27 16:15:20,009 [inflora.py] => 6 layer constraint size: 94
2025-11-27 16:15:20,009 [inflora.py] => 7 layer constraint size: 110
2025-11-27 16:15:20,009 [inflora.py] => 8 layer constraint size: 166
2025-11-27 16:15:20,009 [inflora.py] => 9 layer constraint size: 229
2025-11-27 16:15:20,009 [inflora.py] => 10 layer constraint size: 265
2025-11-27 16:15:20,009 [inflora.py] => 11 layer constraint size: 162
2025-11-27 16:15:20,009 [inflora.py] => 12 layer constraint size: 159
2025-11-27 16:15:20,012 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:15:20,015 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:15:20,026 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:15:20,033 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:15:20,041 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:15:20,047 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:15:20,054 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:15:20,060 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:15:20,067 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:15:20,073 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:15:20,080 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:15:20,083 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:16:04,276 [inflora.py] => Exemplar size: 0
2025-11-27 16:16:04,277 [trainer.py] => No NME accuracy.
2025-11-27 16:16:04,277 [trainer.py] => CNN: {'total': np.float64(0.13), '00-09': np.float64(1.2), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), '40-49': np.float64(0.0), '50-59': np.float64(0.0), '60-69': np.float64(0.0), '70-79': np.float64(0.0), '80-89': np.float64(0.0), 'old': np.float64(0.15), 'new': np.float64(0.0)}
2025-11-27 16:16:04,277 [trainer.py] => CNN top1 curve: [np.float64(99.3), np.float64(7.2), np.float64(4.37), np.float64(1.23), np.float64(2.36), np.float64(1.47), np.float64(2.44), np.float64(3.29), np.float64(0.13)]
2025-11-27 16:16:04,277 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(18.65), np.float64(20.2), np.float64(12.85), np.float64(12.42), np.float64(9.73), np.float64(9.27), np.float64(7.26), np.float64(4.89)]

2025-11-27 16:16:04,277 [trainer.py] => Average Accuracy (CNN): 13.532222222222224 

2025-11-27 16:16:04,279 [trainer.py] => All params: 111194651
2025-11-27 16:16:04,281 [trainer.py] => Trainable params: 192010
2025-11-27 16:16:04,281 [inflora.py] => Learning on 90-100
2025-11-27 16:16:23,869 [inflora.py] => Parameters to be updated: {'image_encoder.blocks.7.attn.lora_B_v.9.weight', 'image_encoder.blocks.11.attn.lora_B_k.9.weight', 'image_encoder.blocks.2.attn.lora_B_k.9.weight', 'image_encoder.blocks.0.attn.lora_B_k.9.weight', 'image_encoder.blocks.11.attn.lora_B_v.9.weight', 'image_encoder.blocks.4.attn.lora_B_k.9.weight', 'image_encoder.blocks.10.attn.lora_B_v.9.weight', 'classifier_pool.9.bias', 'classifier_pool.9.weight', 'image_encoder.blocks.9.attn.lora_B_v.9.weight', 'image_encoder.blocks.4.attn.lora_B_v.9.weight', 'image_encoder.blocks.5.attn.lora_B_k.9.weight', 'image_encoder.blocks.1.attn.lora_B_k.9.weight', 'image_encoder.blocks.0.attn.lora_B_v.9.weight', 'image_encoder.blocks.7.attn.lora_B_k.9.weight', 'image_encoder.blocks.8.attn.lora_B_k.9.weight', 'image_encoder.blocks.1.attn.lora_B_v.9.weight', 'image_encoder.blocks.9.attn.lora_B_k.9.weight', 'image_encoder.blocks.3.attn.lora_B_k.9.weight', 'image_encoder.blocks.5.attn.lora_B_v.9.weight', 'image_encoder.blocks.2.attn.lora_B_v.9.weight', 'image_encoder.blocks.10.attn.lora_B_k.9.weight', 'image_encoder.blocks.3.attn.lora_B_v.9.weight', 'image_encoder.blocks.6.attn.lora_B_v.9.weight', 'image_encoder.blocks.6.attn.lora_B_k.9.weight', 'image_encoder.blocks.8.attn.lora_B_v.9.weight'}
2025-11-27 16:22:02,155 [inflora.py] => Task 9, Epoch 10/10 => Loss 0.159, Train_accy 95.44
2025-11-27 16:22:19,738 [inflora.py] => Threshold: 0.995
2025-11-27 16:22:25,260 [inflora.py] => ----------------------------------------
2025-11-27 16:22:25,260 [inflora.py] => Gradient Constraints Summary
2025-11-27 16:22:25,260 [inflora.py] => ----------------------------------------
2025-11-27 16:22:25,260 [inflora.py] => 1 layer constraint size: 10
2025-11-27 16:22:25,260 [inflora.py] => 2 layer constraint size: 24
2025-11-27 16:22:25,261 [inflora.py] => 3 layer constraint size: 45
2025-11-27 16:22:25,261 [inflora.py] => 4 layer constraint size: 63
2025-11-27 16:22:25,261 [inflora.py] => 5 layer constraint size: 89
2025-11-27 16:22:25,261 [inflora.py] => 6 layer constraint size: 134
2025-11-27 16:22:25,261 [inflora.py] => 7 layer constraint size: 168
2025-11-27 16:22:25,261 [inflora.py] => 8 layer constraint size: 248
2025-11-27 16:22:25,261 [inflora.py] => 9 layer constraint size: 332
2025-11-27 16:22:25,261 [inflora.py] => 10 layer constraint size: 383
2025-11-27 16:22:25,261 [inflora.py] => 11 layer constraint size: 274
2025-11-27 16:22:25,261 [inflora.py] => 12 layer constraint size: 266
2025-11-27 16:22:25,264 [inflora.py] => Layer 1 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:22:25,267 [inflora.py] => Layer 2 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:22:25,272 [inflora.py] => Layer 3 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:22:25,277 [inflora.py] => Layer 4 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:22:25,341 [inflora.py] => Layer 5 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:22:25,344 [inflora.py] => Layer 6 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:22:25,348 [inflora.py] => Layer 7 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:22:25,353 [inflora.py] => Layer 8 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:22:25,358 [inflora.py] => Layer 9 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:22:25,362 [inflora.py] => Layer 10 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:22:25,365 [inflora.py] => Layer 11 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:22:25,369 [inflora.py] => Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2025-11-27 16:23:12,850 [inflora.py] => Exemplar size: 0
2025-11-27 16:23:12,850 [trainer.py] => No NME accuracy.
2025-11-27 16:23:12,851 [trainer.py] => CNN: {'total': np.float64(1.38), '00-09': np.float64(13.8), '10-19': np.float64(0.0), '20-29': np.float64(0.0), '30-39': np.float64(0.0), '40-49': np.float64(0.0), '50-59': np.float64(0.0), '60-69': np.float64(0.0), '70-79': np.float64(0.0), '80-89': np.float64(0.0), '90-99': np.float64(0.0), 'old': np.float64(1.53), 'new': np.float64(0.0)}
2025-11-27 16:23:12,851 [trainer.py] => CNN top1 curve: [np.float64(99.3), np.float64(7.2), np.float64(4.37), np.float64(1.23), np.float64(2.36), np.float64(1.47), np.float64(2.44), np.float64(3.29), np.float64(0.13), np.float64(1.38)]
2025-11-27 16:23:12,851 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(18.65), np.float64(20.2), np.float64(12.85), np.float64(12.42), np.float64(9.73), np.float64(9.27), np.float64(7.26), np.float64(4.89), np.float64(5.14)]

2025-11-27 16:23:12,851 [trainer.py] => Average Accuracy (CNN): 12.317 

